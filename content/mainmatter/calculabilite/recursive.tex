\chapter{Fonctions récursives, machines de Turing}
\label{chp.recur}

\minitoc

\lettrine{C}{e} chapitre est celui commençant à traiter la calculabilité à
proprement parler. Jusque là, nous avons vu des versions simples d'automates, et
de langages traités par ces automates, pour introduire donner une meilleure
connaissance du traitement des mots par des automates.

Les langages algébriques (et encore plus les langages rationnels) restent
restreints. Par exemple, un langage tel que $\{a^nb^nc^n\mid n \in \mathbb N\}$
n'est pas algébrique, bien qu'il existe clairement un algorithme permettant de
le reconnaître. On souhaite donc trouver une notion plus forte et expressive de
fonction.

Cette notion plus forte est celle de fonction calculable, que nous allons voir
dans ce chapitre à travers les fonctions récursives en premier lieu, puis par
les machines de Turing.

Une fonction calculable est une version mathématique de l'idée intuitive que
l'on se fait de \og fonction programmable sur un ordinateur\fg. Bien sûr, le
caractère mathématique pousse à certaines généralisations (comme le fait que le
modèle mathématique a une mémoire non bornée), mais il reste important, pour
fonder son intuition des fonctions calculables, de garder à l'esprit qu'une
fonction calculable n'est rien d'autre qu'une fonction obtenue en exécutant un
programme d'un langage de programmation suffisamment expressif (tel que
C, Python, Ocaml \latinexpr{etc}).

\section{Fonctions primitives récursives}

Avant d'introduire les fonctions récursives, nous en donnons une version faible
mais très importante~: les fonctions primitives récursives (abrégées en
fonctions RP).

Si l'on imagine une fonction calculable comme un programme
C ou Python, une fonction RP est un programme n'employant comme seule boucle que
la boucle \texttt{for}. Comme nous le verrons, ces
fonctions ne donnent pas une expressivité aussi forte qu'on pourrait le souhaiter, d'où
l'introduction plus tard des fonctions récursives. Cependant, cette première notion de
calcul est centrale pour plusieurs raisons~:
\begin{itemize}
\item elle permet en fait d'exprimer toutes les fonctions qu'un ordinateur peut
  programmer à l'exception d'une unique instruction, que l'on peut rapprocher d'une
  boucle \texttt{while}~;
\item elle contient déjà la plupart des fonctions qui nous sont utiles en mathéamtiques,
  et possède de meilleures propriétés (par exemple un programme n'utilisant que des
  boucles \texttt{for} est toujours sûr de terminer).
\end{itemize}

Nous allons d'abord voir la notion de fonction RP la plus classique (on peut retrouver
les mêmes définitions par exemple dans \cite{cori1993logique}), puis nous introduirons
une version généralisée de cette classe de fonctions. L'intérêt premier de cette version
généralisée est de faciliter le travail d'encodage dans les futurs chapitres, et de
mettre en valeur la classe des fonctions RP non comme un pur objet logique mais bien
comme un modèle de calcul intermédiaire entre les langages algébriques et les langages
récursifs (que nous verrons ensuite).

Historiquement, la notion de fonction primitive récursive est apparue avant celle des
fonctions calculables, notamment dans \cite{skolem1923begrundung} qui a mis en avant
l'importance et la polyvalence des définitions par récurrence. \`A l'époque, de telles
fonctions étaient simplement appelées \og fonctions définies par récurrence\fg car, du
fait de l'absence de la notion de fonction récursive générale, l'adjectif
\og primitive\fg n'avait pas encore de raison d'être introduit. Notons malgré tout que
durant une assez longue période, les fonctions que l'on appelle maintenant récursives
primitives étaient appelées récursives, et les fonctions que l'on appelle maintenant
récursives étaient appelées récursives générales, comme introduites dans
\cite{godel1934undecidable}.

\subsection{Définitions et premières fonctions}

Donnons dès maintenant la définition de la classe RP.

\begin{definition}[Fonctions primitives récursives \cite{skolem1923begrundung}]
  On définit la classe
  $\RecP\subseteq \bigcup_{n \in \mathbb N}\Funct(\mathbb N^n,\mathbb N)$
  comme la plus petite classe telle que~:
  \begin{itemize}
  \item pour toutes les projections
    \[\begin{array}{ccccc}
    \pi_k^n &:& \mathbb N^n &\longrightarrow& \mathbb N\\
    & & (x_1,\ldots,x_n) & \longmapsto & x_k
    \end{array}\]
    avec $n,k\in \mathbb N, \pi_k^n \in \RecP$.
  \item pour tout $n \in \mathbb N$, en notant
    $\mathrm k_0^n : \mathbb N^p \to \mathbb N$ la fonction nulle,
    $\mathrm k_0^n \in \RecP$.
  \item la fonction $n \mapsto n + 1$ est primitive récursive~: $\sucs\in\RecP$.
  \item si $f_1,\ldots,f_n : \mathbb N^k \to \mathbb N$ sont des fonctions RP
    et $g : \mathbb N^n \to \mathbb N$ est une fonction RP, alors la fonction
    \[\begin{array}{ccccc}
    g \circ (f_1,\ldots,f_n) & : & \mathbb N^k &\longrightarrow & \mathbb N\\
    & & (x_1,\ldots,x_k) & \longmapsto &
    g(f_1(x_1,\ldots,x_k),\ldots,f_n(x_1,\ldots,x_k))
    \end{array}\]
    est elle aussi RP.
  \item si $f : \mathbb N^k \to \mathbb N$ et
    $g : \mathbb N^{k+2} \to \mathbb N$ sont des fonctions RP, alors la fonction
    \[\begin{array}{ccccc}
    \rec(f,g) & : & \mathbb N^{k+1} &\longrightarrow & \mathbb N \\
    & & (x_1,\ldots,x_k,0) &\longmapsto & f(x_1,\ldots,x_k)\\
    & & (x_1,\ldots,x_k,y+1) & \longmapsto &
    g(x_1,\ldots,x_k,y,\rec(f,g)(x_1,\ldots,x_k,y))
    \end{array}\]
    est elle aussi RP. On appelle cette opération la récursion primitive.
  \end{itemize}
\end{definition}

\begin{remark}
  Comme toujours, on identifie $\mathbb N^0 \to \mathbb N$ avec $\mathbb N$.
  Ainsi on peut définir une fonction $\mathbb N \to \mathbb N$ à partir d'une
  constante $x_0 \in \mathbb N$ et d'une fonction
  $f_s : \mathbb N^2 \to \mathbb N$.
\end{remark}

\begin{remark}
  Toute fonction RP est une fonction totale, puisque les opérations permettant
  de construire de nouvelles fonctions RP conservent la totalité, et les
  fonctions RP de base sont totales.
\end{remark}

On peut donc, dès lors, donner plusieurs fonctions RP élémentaires.

\begin{proposition}
  Les fonctions suivantes sont RP~:
  \begin{itemize}
  \item pour tout $n \in \mathbb N$ et tout $p \in \mathbb N$, la fonction
    constante
    \[\begin{array}{ccccc}
    \mathrm k_n^p &:& \mathbb N^p&\longrightarrow &\mathbb N\\
    & & (x_1,\ldots,x_p) &\longmapsto & n
    \end{array}\]
  \item $+ : \mathbb N^2 \to \mathbb N$
  \item $\times : \mathbb N^2 \to \mathbb N$
  \item $\exp : \mathbb N^2 \to \mathbb N$
  \end{itemize}
\end{proposition}

\begin{proof}
  Pour les fonctions constantes, il nous suffit de composer $n$ fois la fonction
  $\sucs$ à la fonction nulle $\mathrm k_0^p$.
  
  On sait que les autres fonctions souhaitées sont définies par ces équations~:
  \begin{itemize}
  \item $\forall n \in \mathbb N, n+0 = n$
  \item $\forall n,m \in \mathbb N, n + \sucs(m) = \sucs(n+m)$
  \item $\forall n \in \mathbb N, n \times 0 = 0$
  \item $\forall n,m \in \mathbb N, n \times \sucs(m) = n + (n\times m)$
  \item $\forall n \in \mathbb N, \exp(n,0) = 1$
  \item $\forall n,m\in \mathbb N, \exp(n,\sucs(m)) = n \times \exp(n,m)$
  \end{itemize}
  On définit les fonctions suivantes~:
  \begin{itemize}
  \item $+ \defeq \rec(\pi_1^1,\sucs\circ \pi_3^3)$
  \item $\times \defeq \rec(k_0^1,+ \circ (\pi_2^3,\pi_3^3))$
  \item $\exp \defeq \rec(k_1^1,\times\circ (\pi_2^3,\pi_3^3))$
  \end{itemize}
  Il est direct de vérifier que ces fonctions vérifient les équations attendues.
\end{proof}

A partir de ces fonctions élémentaires, on peut construire les fonctions de
somme et de produit.

\begin{proposition}
  Les fonctions suivantes sont RP~:
  \[
  \begin{array}{ccccc}
    \Sigma^p &: & \mathbb N^p &\longrightarrow & \mathbb N \\
    & & (x_1,\ldots,x_p) &\longmapsto & \sum_{i = 1}^p x_i
  \end{array}\qquad
  \begin{array}{ccccc}
    \Pi^p &: & \mathbb N^p &\longrightarrow & \mathbb N\\
    & & (x_1,\ldots,x_p) &\longmapsto & \prod_{i = 1}^p x_i
  \end{array}
  \]
\end{proposition}

\begin{proof}
  On prouve par récurrence sur $p$ que chaque $\Sigma^p,\Pi^p$ est une fonction
  RP~:
  \begin{itemize}
  \item dans le cas où $p = 0$, on a simplement deux constantes, respectivement
    $0$ et $1$, qui sont RP.
  \item supposons que $\Sigma^p$ est RP, alors on peut définir $\Sigma^{p+1}$
    par
    \[\Sigma^{p+1} \defeq +\circ
    (\Sigma^p \circ (\pi_1^{p+1},\ldots,\pi_p^{p+1}),
    \pi_{p+1}^{p+1})\]
    et $\Pi^{p+1}$ par
    \[\Pi^{p+1}\defeq \times\circ
    (\Pi^p \circ (\pi_1^{p+1},\ldots,\pi_p^{p+1}),
    \pi_{p+1}^{p+1})\]
  \end{itemize}
  Les deux fonctions sont donc RP.
\end{proof}

\begin{exercise}
  Soit une fonction RP $f : \mathbb N^n \to \mathbb N$. Montrer que la
  fonction
  \[\begin{array}{ccccc}
  \Sigma^f &: &\mathbb N^{n+1} &\longrightarrow & \mathbb N\\
  & & (x_1,\ldots,x_n,p) &\longmapsto & \sum_{i = 1}^p f(x_1,\ldots,x_n,i)
  \end{array}\]
  est une fonction RP. Montrer la même chose pour la fonction $\Pi^f$ dans
  laquelle la somme est remplacée par le produit.
\end{exercise}

D'autres fonctions arithmétiques parmi les plus élémentaires sont facilement
prouvables comme étant RP.

\begin{proposition}
  Les fonctions $\min,\max : \mathbb N^2 \to \mathbb N$, la fonction
  $d : \mathbb N^2 \to \mathbb N$ définie par $d(n,m) = | n - m |$,
  ainsi que la fonction
  \[\begin{array}{ccccc}
  - &: & \mathbb N^2 &\longrightarrow & \mathbb N\\
  & & (n,0) & \longmapsto & n\\
  & & (0,\sucs(m)) &\longmapsto & 0\\
  & & (\sucs(n),\sucs(m)) &\longmapsto & n - m
  \end{array}\]
  sont RP.
\end{proposition}

\begin{proof}
  On commence par prouver que $-$ est RP. Pour cela, on définit d'abord la
  fonction prédécesseur, qui envoie $0$ sur $0$ et $\sucs(n)$ sur $n$~:
  \[p \defeq \rec(\mathrm k_0^0,\pi_1^2)\]
  A partir de cette fonction $p$, on définit la fonction $-$ comme son
  itération~:
  \[- \defeq \rec(\pi_1^1,p \circ \pi_3^3)\]
  On voit qu'alors, $n - 0 = n$ pour tout $n \in \mathbb N$. On montre ensuite
  par récurrence sur $m$ que $0 - m = 0$~:
  \begin{itemize}
  \item $0 - 0 = 0$
  \item si $0 - m = 0$, alors $0 - \sucs(m) = p(0-m) = p(0) = 0$
  \end{itemize}
  Il nous reste alors à montrer que $\sucs(n) - \sucs(m) = n - m$. On raisonne
  par induction sur $m$~:
  \begin{itemize}
  \item $\sucs(n) - \sucs(0) = p(\sucs(n) - 0) = p(\sucs(n)) = n = n - 0$
  \item supposons que $\sucs(n) - \sucs(m) = n - m$, alors
    \[
    \sucs(n) - \sucs(\sucs(m)) = p(\sucs(n) - \sucs(m)) = p(n - m)
    = n - \sucs(m)
    \]
  \end{itemize}
  Donc $-$ est RP.

  A partir de cette définition de $-$, on peut prouver que $n-m = \max(0,n-m)$
  (nous considérons la preuve suffisamment directe pour la laisser en
  exercice). On peut alors définir $d(n,m) = (n - m) + (m - n)$.

  On peut vérifier que pour tous $n,m$, on a les deux équations suivantes~:
  \[\min(n,m) = \frac{1}{2}(n + m - |n - m|)\qquad
  \max(n,m) = \frac{1}{2}(n + m + |n - m|)\]
  donc les fonctions $\min$ et $\max$ s'écrivent comme
  \begin{align*}
    \min &\defeq \mathrm{demi}\circ - \circ (+,d)\\
    \max &\defeq \mathrm{demi}\circ + \circ (+,d)
  \end{align*}
  On en déduit que les fonctions souhaitées sont RP.
\end{proof}

\begin{exercise}
  Montrer que les fonctions $\min$ et $\max$ sur un $n$-uplet sont encore des
  fonctions RP.
\end{exercise}

\begin{exercise}
  Vérifier que la fonction
  \[\begin{array}{ccccc}
  \mathrm{demi} & : & \mathbb N &\longrightarrow & \mathbb N\\
  & & n &\longmapsto & \displaystyle\left\lfloor \frac{n}{2}\right\rfloor
  \end{array}\]
  est bien une fonction RP.
\end{exercise}

\begin{exercise}
  Montrer que la fonction $q : \mathbb N^2 \to \mathbb N$ et la fonction
  $r : \mathbb N^2 \to \mathbb N$, renvoyant respectivement le quotient et le
  reste de la division euclidienne d'un entier par un autre, sont des fonctions
  RP.
\end{exercise}

Attardons-nous maintenant sur la notion de prédicat RP. On a vu qu'une fonction
RP était une certaine fonction $\mathbb N^n \to \mathbb N$, mais il est aussi
intéressant de considérer à la place de fonctions des relations
$R\subseteq \mathbb N^n$. On adapte donc notre notion de RP à ces relations.

\begin{definition}[Relation RP]
  On dit qu'une relation $R \subseteq \mathbb N^n$ est RP si sa fonction
  caractéristique $\chi_R : \mathbb N^n \to \btwo$ est une fonction RP.
\end{definition}

\begin{remark}
  On parlera aussi d'ensemble RP ou de partie RP, ce dernier cas plutôt pour
  parler de partie de $\mathbb N$.
\end{remark}

Les relations RP se comportent bien vis à vis de la logique classique, au sens
de la proposition suivante.

\begin{proposition}\label{prop.PRBool}
  Pour tout $n \in \mathbb N$, l'ensemble des relations RP sur $\mathbb N^n$
  est une sous-algèbre de Boole de $\powerset(\mathbb N^n)$.
\end{proposition}

\begin{proof}
  On cherche donc à prouver que les relations RP sont stables par intersection,
  union et complément, et que $\mathbb N^n$ et $\varnothing$ sont des relations
  RP. Les deux derniers points sont directs puisque ces deux relations
  correspondent respectivement à $\mathrm k_1^n$ et $\mathrm k_0^n$.

  Soient $R,S$ deux relations RP, alors~:
  \[\forall n_1,\ldots,n_p \in \mathbb N,
  \begin{cases}
    \chi_{R\cap S}(n_1,\ldots,n_p) =
    \min(\chi_R(n_1,\ldots,n_p),\chi_S(n_1,\ldots,n_p))\\
    \chi_{R\cup S}(n_1,\ldots,n_p) =
    \max(\chi_R(n_1,\ldots,n_p),\chi_S(n_1,\ldots,n_p))
  \end{cases}
  \]
  donc $R\cap S$ et $R\cup S$ sont RP, en composant par $\min$ et $\max$,
  respectivement.

  De plus,
  \[\forall n_1,\ldots,n_p \in \mathbb N,
  \chi_{\mathbb N^p\setminus R}(n_1,\ldots,n_p) = 1 - \chi_R(n_1,\ldots,n_p)\]
  donc $\mathbb N^p \setminus R$ est aussi RP, en composant par
  $x \mapsto 1 - x$.

  Ainsi les relations RP forment une algèbre de Boole pour les opérations
  ensemblistes usuelles.
\end{proof}

\begin{proposition}
  Les relations $\triangle \defeq \{(x,x) \mid x \in \mathbb N^n\}$ et
  $\leq \defeq \{(n,m) \mid n \leq m\}$ sont RP.
\end{proposition}

\begin{proof}
  On prouve d'abord que $\leq$ est RP. Pour cela, on remarque que $n \leq m$
  exactement lorsque $n - m \leq 0$, c'est-à-dire lorsque $n - m = 0$.
  En prenant alors $(n,m) \mapsto 1 - (n - m)$, on a bien une fonction RP à
  valeurs dans $\btwo$ et qui coïncide avec $\chi_\leq$. Pour montrer que
  la relation $\triangle$ est aussi RP, il suffit de remarquer que
  \[(n,m) \in \triangle \iff (n \leq m) \land (m \leq n)\]
  et d'utiliser la \cref{prop.PRBool} pour en déduire le résultat.
\end{proof}

\begin{exercise}
  Montrer que $\triangle^n \defeq
  \{(n,\ldots,n) \in \mathbb N^n\mid n \in \mathbb N\}$ est
  une relation RP.
\end{exercise}

Grâce à ces propriétés de base, on sait déjà que des formules sans
quantification utilisant l'égalité et l'inégalité comme symbole de relation
sont, en s'interprétant dans la structure $\mathbb N$, des relations RP.

On verra qu'il n'est pas possible de rajouter n'importe quelle quantification,
mais le résultat suivant est déjà un résultat particulièrement fort~: une
quantification bornée sur une relation RP reste une relation RP.

\begin{proposition}
  Soit une relation RP $R\subseteq \mathbb N^{n+1}$. On définit les fonctions
  \[\begin{array}{ccccc}
  \exists R&:&\mathbb N^{n+1} & \longrightarrow & \btwo\\
  & & (x_1,\ldots,x_n,y) &\longmapsto &
  \begin{cases}
    1 \text{ si } \exists z < y, R(x_1,\ldots,x_n,z)\\
    0 \text{ sinon }
  \end{cases}
  \end{array}\]
  \[\begin{array}{ccccc}
  \forall R & : & \mathbb N^{n+1} & \longrightarrow & \btwo\\
  & & (x_1,\ldots,x_n,y) &\longmapsto &
  \begin{cases}
    1 \text{ si } \forall z < y, R(x_1,\ldots,x_n,z)\\
    0 \text{ sinon }
  \end{cases}
  \end{array}\]
  Ces deux fonctions sont RP.
\end{proposition}

\begin{proof}
  On construit les deux fonctions par récursion primitive~:
  \[\exists R \defeq \rec(\mathrm k_0^n,\max\circ
  (\pi_{n+2}^{n+2},R\circ(\pi_1^{n+2},\ldots,\pi_{n+1}^{n+2})))\]
  \[\forall R \defeq \rec(\mathrm k_1^n,\min\circ
  (\pi_{n+2}^{n+2},R\circ(\pi_1^{n+2},\ldots,\pi_{n+1}^{n+2})))\]
  On montre seulement le fait que la fonction $\exists R$ ainsi définie
  vérifie la propriété voulue, le cas de $\forall$ étant parfaitement analogue.

  On remarque d'abord qu'il n'existe aucun $z < 0$, donc dans le cas de
  $(x_1,\ldots,x_n,0)$ la valeur retournée est $0$. Dans le cas où l'on appelle
  la fonction sur $(x_1,\ldots,x_n,\sucs(y))$, alors on voit qu'il existe
  $z < \sucs (y)$ tel que $R(x_1,\ldots,x_n,z)$ si et seulement s'il existe
  $z < y$ tel que $R(x_1,\ldots,x_n,z)$ ou si $R(x_1,\ldots,x_n,y)$, ce qui
  correspond à l'équation vérifiée dans le cas récursif.
\end{proof}

\begin{exercise}
  Montrer que l'ensemble des nombres premiers est un ensemble RP.
\end{exercise}

On peut aussi construire des instructions conditionnelles sur des relations RP.

\begin{proposition}
  Soit $R \subseteq \mathbb N^n$ une fonction RP et deux fonctions
  $f,g : \mathbb N^n \to \mathbb N$ deux fonctions RP. Alors la fonction
  \[\begin{array}{ccccc}
  \ifrm(R,f,g)& : & \mathbb N^n &\longrightarrow & \mathbb N\\
  & & (x_1,\ldots,x_n) &\longmapsto &
  \begin{cases}
    f(x_1,\ldots,x_n) \text{ si } (x_1,\ldots,x_n) \in R\\
    g(x_1,\ldots,x_n) \text{ sinon }
  \end{cases}
  \end{array}\]
\end{proposition}

\begin{proof}
  On définit $\ifrm$ de la façon suivante~:
  \[\ifrm(R,f,g) \defeq \rec(g,f\circ(\pi_1^{n+2},\ldots,\pi_n^{n+2}))\circ
  (\pi_1^n,\ldots,\pi_n^n,R)\]
  Lorsque $R(x_1,\ldots,x_n) = 0$, la fonction vaut
  $(g\circ (\pi_1^n,\ldots,\pi_n^n)) (x_1,\ldots,x_n)$, c'est-à-dire
  $g(x_1,\ldots,x_n)$. Lorsque $R(x_1,\ldots,x_n) = 1$, la fonction
  vaut $(f\circ (\pi_1^n,\ldots,\pi_n^n))(x_1,\ldots,x_n)$, c'est-à-dire
  $f(x_1,\ldots,x_n)$. D'où le résultat.
\end{proof}

\begin{remark}
  La fonction $\ifrm(R,f,g)$ peut s'appliquer avec une fonction $h$ à la place
  de $R$. La condition sera alors que la valeur retournée par $h$ est non nulle.
\end{remark}

On voit qu'il est possible de passer facilement d'une fonction à un ensemble,
en considérant la fonction caractéristique. Réciproquement, on souhaite avoir
un moyen, étant donné un prédicat, d'en extraire une fonction~: c'est la notion
de minimisation qui nous sera utile.

\begin{definition}[Minimisation, minimisation bornée]
  Soit $R \subseteq \mathbb N^{n+1}$ une relation. On définit la fonction
  partielle de minimisation comme suit~:
  \[\begin{array}{ccccc}
  \mu R & : & \mathbb N^n & \longrightarrow & \mathbb N\\
  & & (x_1,\ldots,x_n) & \longmapsto & \min
  \{ y \in \mathbb N\mid (x_1,\ldots,x_n,y)\in R\}
  \end{array}\]
  où la fonction n'est pas définie lorsque l'ensemble sur lequel est pris le
  minimum est vide.

  On appelle minimisation bornée la fonction totale suivante~:
  \[\begin{array}{ccccc}
  \mu_B R & : & \mathbb N^{n+1} & \longrightarrow &\mathbb N\\
  & & (x_1,\ldots,x_n,y) & \longmapsto & \min
  \{ z < y \mid (x_1,\ldots,x_n,z) \in R\}
  \end{array}\]
  où la fonction vaut $0$ lorsque l'ensemble sur lequel est pris le minimum est
  vide.
\end{definition}

La minimisation en général n'est pas RP, mais la minimisation bornée l'est. De
plus, le fait que la fonction n'est pas définie dans le cas de $\mu$ est dû
au fait que si l'on songe à nos fonctions comme à des algorithmes, et à $R$
comme à un algorithme de décision, il est impossible de savoir (en temps fini)
s'il existe ou non un certain $y$ tel que $R(x_1,\ldots,x_n,y)$. Au contraire,
dans le cas de la minimisation bornée, il est possible de le vérifier en temps
fini, et on peut donc donner une valeur dans le cas où l'ensemble est vide.

\begin{proposition}
  Soit $R\subseteq \mathbb N^{n+1}$ une relation RP. La fonction $\mu_B R$ est
  une fonction RP.
\end{proposition}

\begin{proof}
  On définit $\mu_B R$ par récursion primitive. Dans le cas où $y = 0$, alors
  l'ensemble $\{ z < 0 \mid (x_1,\ldots,x_n,z) \in R\}$ est vide donc la
  fonction retourne $0$. Dans le cas inductif, lorsque $y = \sucs(y')$, le
  minimum de l'ensemble est soit le minimum de
  $\{ z < y' \mid (x_1,\ldots,x_n,z)\in R\}$ si cet ensemble est non vide, soit
  $y'$ si $(x_1,\ldots,x_n,y') \in R$ si cet ensemble est non vide, soit $0$. On
  pourrait se contenter de cet algorithme, qui nous fait recalculer en
  permanence l'habitation des ensembles. A la place, on va construire une
  fonction qui retourne $\sucs(m)$ où $m$ est le minimum s'il existe, et $0$
  sinon~:
  \[f_0 \defeq \rec(\km_0^n,\ifrm(\pi_{n+2}^{n+2},\pi_{n+2}^{n+2},
  \times\circ(R\circ(\pi_1^{n+2},\ldots,\pi_{n+1}^{n+2}),
  \sucs\circ \pi_{n+1}^{n+2})))\]
  On définit alors $\mu_B R$ simplement par $p\circ f_0$, où $p$ est la
  fonction précédesseur définie plus haut.
\end{proof}

Avec les outils présents, on peut montrer que la bijection de Cantor introduite
dans la \cref{def.bij.Cantor} est une fonction RP.

\begin{proposition}
  La bijection de Cantor $\alpha : \mathbb N \times \mathbb N \to \mathbb N$
  est une fonction RP. Les deux fonctions
  $\pi_1',\pi_2' : \mathbb N \to \mathbb N$ telles que
  $(\pi_1'(\alpha(n,m)),\pi_2'(\alpha(n,m))) = (n,m)$ sont elles aussi RP.
\end{proposition}

\begin{proof}
  On sait que la fonction $f_1 : k \mapsto \sum_{i = 1}^k i$ est RP. On peut
  alors définir $\alpha$~:
  \[\alpha \defeq + \circ (f_1\circ +,\pi_2^2)\]
  Ainsi $\alpha$ est bien une fonction RP.

  Comme la situation est symétrique entre $\pi_1'$ et $\pi_2'$, on montre
  seulement que $\pi_1'$ est RP. Soit $n,m\in \mathbb N$ et $a = \alpha(n,m)$.
  Le prédicat $k = \pi_1'(a)$ revient à $\exists p \leq a,\alpha(k,p) = a$ car
  $p \leq \alpha(p,i)$ pour tout $i\in\mathbb N$. De plus, pour tout
  $a\in \mathbb N$, il existe effectivemnet $n,m$ tels que $a = \alpha(n,m)$,
  donc $\{k \leq a \mid \exists p\leq a, \alpha(k,p) = a\}$
  contient exactement un élément, que l'on peut récupérer par minimisation.
  On en déduit donc
  \[\pi_1' \defeq \mu_B (\exists(\triangle\circ
  (\alpha\circ (\pi_2^3,\pi_3^3), \pi_1^3)))\circ (\pi_1^1,\pi_1^1)\]
  Donc $\pi_1'$ est une fonction RP.
\end{proof}

\begin{exercise}
  Montrer que chaque $\alpha_n$ est aussi une fonction RP, et que chaque
  projection $\varpi_i^n$ telle que $\varpi_i^n(\alpha_n(x_1,\ldots,x_n)) = x_i$,
  est une fonction RP.
\end{exercise}

Avec ces données, on se rend compte que le fait d'avoir des fonctions
$\mathbb N^n \to \mathbb N$ n'apporte pas réellement plus d'expressivité que
d'avoir simplement des fonctions $\mathbb N \to \mathbb N$, puisque toutes les
fonctions RP $f : \mathbb N^k \to \mathbb N$ peuvent se réécrire en une
composée de fonctions
$n \mapsto (\varpi_1^p(n),\ldots,\varpi_p^p(n))
\overset{f}{\mapsto} f(n_1,\ldots,n_p)$ elle aussi
RP. Bien sûr, il est toujours nécessaire de définir les fonctions avec plusieurs
coordonnées de par la définition même des fonctions RP (puisqu'en particulier
la récursion primitive utilise un appel sur une seule coordonnée en laissant les
autres statiques).

\subsection{Codages primitifs récursifs}

Dans cette sous-section, on va définir une notion généralisée de fonctions
primitives récursives, où les fonctions ont comme domaine et codomaine d'autres
ensembles que $\mathbb N$. Comme on peut voir $\mathbb N$ comme le monoïde libre
à un élément, $\{*\}^\star$, on peut généraliser les définitions facilement en
remplaçant $\mathbb N$ par $\Sigma^\star$ pour un ensemble fini $\Sigma$.

Les définitions et propositions données dans cette sous-section sont l'\oe uvre
des auteurs de ce livre, d'où l'absence de références bibliographiques.
L'intérêt de ces constructions est avant tout de faciliter des notions de
codage, en remplaçant de futures preuves fastidieuses en 3 résultats
principaux~:
\begin{itemize}
\item généraliser les fonctions récursives primitives sur des alphabets
  différents ne change pas la classe des fonctions RP de la forme
  $\mathbb N^n \to \mathbb N$,
\item les langages algébriques sont primitifs récursifs,
\item les fonctions définies par induction par la \cref{prop.PU.gram} sont
  compatibles avec la classe des fonctions RP.
\end{itemize}
Le deuxième résultat est déjà plus élégant que si l'on se restreignait aux
fonctions $\mathbb N^n \to \mathbb N$, étant donné que l'exprimer uniquement
avec cette classe de fonctions demanderait de définir des codages préalables.
Ne pas passer par des codages supplémentaires pour exprimer ces résultats donne
un aspect plus intrinsèque à notre notion de fonctions PR~: les langages que
cette notion engendrent sont effectivement plus fort que les langages
algébriques.

Cependant, le réel atout de cette généralisation est de permettre de considérer
des opérations \og syntaxiques\fg sur des langages algébriques en restant dans
une classe plus restreinte que ce que nous verrons dans la suite du chapitre.
De plus, grâce au premier des trois résultats, on pourra montrer que toutes ces
opérations peuvent se traduire en des opérations sur
$\mathbb N^n \to \mathbb N$ modulo un codage prélable, sans avoir à prouver à
nouveau que de telles opérations sont bien des fonctions RP. On le verra dans le
CHAPITRE HIERARCHIE ARITHMETIQUE, mais ces résultats donneront en corollaire
beaucoup de résultats techniques.

\begin{definition}[Fonctions récursives primitives généralisées]
  On définit la classe des fonctions récursives primitives généralisées
  (RPG) comme la plus petite classe de fonctions
  $(\Sigma_1)^\star\times\cdots\times(\Sigma_n)^\star\to \Sigma^\star$
  où $\Sigma_1,\ldots,\Sigma_n,\Sigma$ sont des ensembles finis, telle que~:
  \begin{itemize}
  \item chaque fonction
    \[\begin{array}{ccccc}
    \pi_k^n & : &\displaystyle \left(\prod_{i = 1}^n (\Sigma_i)^\star\right)&
    \longrightarrow & (\Sigma_k)^\star\\
    & & (u_1,\ldots,u_n) & \longmapsto & u_k
    \end{array}\]
    est une fonction RPG.
  \item pour tout $\Sigma$ et $a \in \Sigma$, la fonction
    \[\begin{array}{ccccc}
    \cons_a & : & \Sigma^\star & \longrightarrow & \Sigma^\star\\
    & & u & \longmapsto & u\star a
    \end{array}\]
    est une fonction RPG.
  \item pour tous $\Sigma_1,\ldots,\Sigma_n,\Sigma$, la fonction
    \[\begin{array}{ccccc}
    \km_\varepsilon^n &: & \displaystyle
    \left(\prod_{i = 1}^n (\Sigma_i)^\star\right) &\longrightarrow& \Sigma^\star\\
    & & (u_1,\ldots,u_n) & \longmapsto & \varepsilon
    \end{array}\]
    est une fonction RPG.
  \item si $f_k : \prod_{i = 1}^n (\Sigma_i)^\star \to (\Gamma_k)^\star$ est une
    fonction RPG pour chaque $k = 1,\ldots,p$, et
    $g : \prod_{i = 1}^p (\Gamma_i)^\star \to \Sigma$ est une fonction RPG, alors
    \[\begin{array}{ccccc}
    g\circ (f_1,\ldots,f_n) & : & \displaystyle
    \left(\prod_{i = 1}^n (\Sigma_i)^\star\right) &
    \longrightarrow & \Sigma\\
    & & (u_1,\ldots,u_n) &\longmapsto &
    g(f_1(u_1,\ldots,u_n),\ldots,f_p(u_1,\ldots,u_n))
    \end{array}\]
    est une fonction RPG.
  \item si $f : \prod_{i = 1}^p (\Sigma_i)^\star \to \Sigma^\star$ est une
    fonction RPG, $\Gamma$ est un ensemble fini et, pour tout $a\in \Gamma$,
    \[g_a : \left(\prod_{i = 1}^p (\Sigma_i)^\star\right)\times \Gamma^\star\times
    \Sigma^\star\to\Sigma^\star\]
    est une fonction RPG, alors la fonction
    \[\rec(f,(g_a)_{a \in \Gamma}) : \left(\prod_{i = 1}^p (\Sigma_i)^\star\right)
    \times \Gamma^\star \longrightarrow \Sigma^\star \]
    vérifiant les équations
    \begin{align*}
      \rec(f,(g_a)_{a\in\Gamma})(u_1,\ldots,u_p,\varepsilon) &=
      f(u_1,\ldots,u_p)\\
      \rec(f,(g_a)_{a\in\Gamma})(u_1,\ldots,u_p,a\star u) &=
      g_a(u_1,\ldots,u_p,u,\rec(f,(g_a)_{a \in \Gamma})(u_1,\ldots,u_p,u))
    \end{align*}
    est une fonction RPG.
  \end{itemize}
\end{definition}

\begin{remark}
  On parle ici de tous les ensembles finis, ce qui est trop grand pour obtenir
  un ensemble, et donc définir un prédicat inductif \og être une fonction RPG\fg
  en utilisant le théorème de Knaster-Tarski. Pour régler ce problème, on
  utilise en réalité comme seuls alphabets les ensembles $n \in \omega$, qui
  représentent déjà tous les ensembles finis à bijection près.

  On peut ensuite considérer la version adaptée à tout ensemble fini en disant
  qu'une fonction $f : \Sigma^\star \to \Gamma^\star$ est RPG lorsque,
  pour toutes bijections $\sigma : \Sigma \to \{0,\ldots,n\}$ et
  $\tau : \Gamma\to\{0,\ldots,k\}$, $\tau\circ f \circ \sigma^{-1}$ est une
  fonction RPG. Nous ne considérerons cependant ici que des ensemble de la forme
  $n \in \omega$, car la généralisation des fonctions RPG ajoute déjà de
  nombreuses lourdeurs, et posséder comme alphabet uniquement les ordinaux finis
  suffit à ce que l'on souhaite faire pour des codages.
\end{remark}

Les fonctions RP sont naturellement un sous-ensemble des fonctions RPG, en
assimilant $\mathbb N$ à $\{0\}^\star$. On va considérer pour cette sous-section
que $\{0\}^\star$ est exactement l'ensemble $\mathbb N$ qu'on manipule dans le
cas des fonctions RP/RPG.

Une question naturelle à se poser est si cette notion de fonctions RPG est
strictement plus forte que celle de fonctions RP~: ça n'est pas le cas, et c'est
ce que nous allons montrer dans un premier temps. Pour montrer cela, on va
construire une notion de traduction entre chaque $\Sigma^\star$ et $\mathbb N$.
La traduction $f_\Sigma : \Sigma^\star \cong \mathbb N$ sera choisie RPG, et de
telle sorte que pour toute fonction $f$ RPG, la fonction associée en utilisant
les traductions pour avoir une fonction $\hat{f} : \mathbb N^n \to \mathbb N$
est RP.

\begin{definition}[Traduction RPG canonique]
  Soit $\Sigma$ un ensemble fini. Il existe une fonction
  $f_\Sigma : \Sigma^\star \to \mathbb N$ telle que~:
  \[\begin{cases}
  f_\Sigma\text{ est bijective }\\
  f_\Sigma\in \RPG\\
  f^{-1}_\Sigma\in\RPG
  \end{cases}\]
  et telle que $f_{\{0\}} = \id_{\mathbb N}$.
\end{definition}

\begin{proof}
  Sans perte de généralité, on considère que $\Sigma = \{0,\ldots,n-1\}$ pour un
  certain $n \in \mathbb N$. L'encodage de la suite $u = a_p\cdots a_1$ va être
  donné par
  \[f_\Sigma \defeq \sum_{i = 0}^{p-1} (a_i + 1) n^i\]
  Tout d'abord, on voit que dans le cas où $n = 1$, c'est-à-dire le cas du
  singleton $\{0\}$, cela nous donne
  \[f_{\{0\}}(0^n) = \sum_{i = 0}^{n-1} 1^i = n\]
  donc $f_{\{0\}} = \id_\mathbb N$.

  On souhaite donc montrer que $f_\Sigma$ est une fonction RPG. Pour cela, on
  va définir pour $k \in \{0,\ldots,n-1\}$ la fonction
  \begin{align*}
  g_k &: \Sigma^\star \times \mathbb N \to \mathbb N\\
  g_k(u,m) &\defeq m \times n + (k + 1)
  \end{align*}
  Alors on peut définir
  \[f_\Sigma \defeq \rec(0,(g_k)_{k\in\{0,\ldots,n-1\}})\]
  On voit alors que $f_\Sigma(\varepsilon) = 0$ et que si
  $f_\Sigma(a_p\cdots a_1) = \sum_{i = 1}^{p-1} (a_i + 1)n^{i-1}$ alors
  \begin{align*}
    f_\Sigma(a_p\cdots a_0) &= n \times f_\Sigma(a_p\cdots a_1) + (a_0 + 1)\\
    &= n \times \left(\sum_{i = 1}^{p-1} (a_i + 1) n^{i-1}\right) + (a_0+1)\\
    &= \left(\sum_{i = 1}^{p-1} (a_i+1) n^i\right) + (a_0+1)\\
    &= \sum_{i = 0}^{p-1} (a_i + 1) n^i\\
  \end{align*}
  D'où le résultat souhaité par induction sur $\Sigma^\star$.

  On va donner un candidat à la fonction $f_\Sigma^{-1}$ et montrer que ce
  candidat est RPG. Pour cela, on montre d'abord qu'il est possible
  de construire la décomposition en base $n$ sur $p$ chiffres d'un nombre $m$
  donné en tant que fonction RPG $\mathbb N \to \{0,\ldots,n-1\}^\star$.

  Pour commencer, il nous faut construre une première fonction~: étant donné un
  nombre $k \in \mathbb N$, on souhaite montrer que la fonction
  \[\begin{array}{ccccc}
  \cons_{k\% n} &: & \Sigma^\star & \longrightarrow & \Sigma^\star\\
  & & u &\longmapsto & u\star (k\% n)
  \end{array}\]
  et RPG, où $k \% n$ désigne le reste de la division euclidienne de $k$ par
  $n$. En réalité, comme $n$ est un nombre fini, il nous suffit d'imbriquer des
  conditions d'égalité de $k \% n$ à chaque nombre dans $i\in\{0,\ldots,n-1\}$
  et, dans chaque cas, d'utiliser la fonction $\cons_i$.

  On définit alors la fonction
  \[\begin{array}{ccccc}
  f_n &: & \mathbb N^2 &\longrightarrow & \Sigma^\star\\
  & & (k,0) & \longmapsto & \varepsilon\\
  & & (k,d + 1) & \longmapsto & \cons_{k\% n}(f_n(k//n,d))
  \end{array}\]
  où $k//n$ est le quotient de la division euclidienne de $k$ par $n$. Il est
  clair que cette fonction est RPG, en utilisant une récursion primitive. On
  souhaite maintenant montrer par récurrence sur $d$ que
  $f_n(k,d)$ est la suite des $d$ chiffres de poids le plus faible de la
  décomposition en base $n$ de $k$~:
  \begin{itemize}
  \item le cas pour $d = 0$, donc $f_n(k,d) = \varepsilon$, est automatique
  \item pour l'hérédité, on remarque d'abord que la décomposition en base
    $n$ de $k$ est la décomposition en base $n$ de $k//n$ suivie de
    $k \% n$. Ainsi, si $f_n(k//n,d)$ est la suite des $d$ chiffres de poids le
    plus faible de la décomposition en base $n$ de $k//n$, alors
    $f_n(k//n,d)\star k\%n$ est la suite des $d + 1$ chiffres de poids le plus
    faible de la décomposition en base $n$ de $k$.
  \end{itemize}
  Donc la décomposition en base $n$ sur $d$ chiffres est bien une fonction RPG.

  On peut maintenant définir la fonction $d : \mathbb N \to \mathbb N$ telle que
  $d(m)$ est le plus petit entier $d$ tel que
  \[m < \sum_{i = 0}^d n^i\]
  Cette fonction est RPG puisqu'il s'agit d'une minimisation, dont une borne
  est donnée par $m$ lui-même étant donné que $m < \sum_{i = 0}^m n^i$.
  On construit ensuite l'entier $m' = m - \sum_{i = 0}^{d(m)-1} n^i$ (comme $d(m)$
  est choisi minimal, la valeur de droite est bien positive) puis le
  mot sur $\{0,\ldots,n-1\}^\star$ donné par la décomposition de $m'$ sur
  $d$ chiffres. On sait donc que cette fonction est RPG.

  Montrons maintenant que les deux fonctions sont réciproques l'une de l'autre.
  Tout d'abord, si on a un entier $m$, $d$ le plus petit entier $d$ tel que
  $m < \sum_{i = 0}^d n^i$ et $a_{d-1}\cdots a_0$ la décomposition en base
  $n$ sur $d$ chiffres de $m - \sum_{i = 0}^{d-1}n^i$, alors
  \[m = \sum_{i=0}^{d-1} (a_i + 1)n^i\]
  donc $f_\Sigma\circ f_\Sigma^{-1} = \id_{\mathbb N}$.

  Réciproquement, si $a_d\cdots a_0\in \Sigma^\star$, alors en notant
  $m = f_\Sigma(a_d\cdots a_0)$, $d(m) = d + 1$ puisque
  \[\sum_{i = 0}^d n^i \leq m \leq \sum_{i = 0}^d (n-1)n^i = n^{d+1} - 1 <
  \sum_{i = 1}^{d+1} n^i\]
  On voit alors que $m - \sum_{i = 0}^d n^i = \sum_{i = 0}^d a_i n^i$, donc la
  décomposition en base $n$ sur $d+1$ chiffres nous donne $a_d\cdots a_0$.

  Ainsi $f_\Sigma$ est une fonction RPG bijective de réciproque RPG.
\end{proof}

On peut alors associer à une fonction RPG $f$ une fonction RPG ne prenant en
argument et ne retournant que des entiers.

\begin{definition}[Fonction RP associée à une fonction RPG]
  Soit
  \[f : \left(\prod_{i = 1}^n (\Sigma_i)^\star\right) \longrightarrow
  \Sigma^\star\]
  une fonction RPG. On appelle sa fonction RP associée la fonction RPG
  \begin{align*}
    \hat f &: \mathbb N^n \to \mathbb N\\
    \hat f &\defeq f_\Sigma \circ f \circ
    (f_{\Sigma_1}^{-1},\ldots,f_{\Sigma_n}^{-1})
  \end{align*}
\end{definition}

L'objectif est donc de montrer que pour toute fonction RPG $f$, la fonction
$\hat f$ est une focntion RP. La preuve se faisant par induction sur la
définition des fonctions RPG, donnons donc une étude sommaire des cas les
plus évidents~:
\begin{itemize}
\item dans le cas des projections, la fonction associée est
  $f_{\Sigma_k}\circ f^{-1}_{\Sigma_k} = \id$.
\item dans le cas de $\cons_a : \Sigma \to \Sigma$, pour
  $\Sigma = \{0,\ldots,n-1\}$ et tout $a \in \Sigma$,
  la fonction $f_\Sigma\circ \cons_a\circ f_\Sigma^{-1}$ est simplement la
  fonction $k \mapsto n\times k + a + 1$. Cette fonction est RP en utilisant les
  résultats précédents.
\item pour la fonction $\km_\varepsilon$, la fonction associée est directement
  $\km_0$.
\item si $g$ et $(h_i)_{i \in \{1,\ldots,p\}}$ sont des fonctions RPG,
  alors on peut simplement remarque que l'égalité
  $\widehat{g\circ (h_i)_i} = \hat g \circ (\hat{h_i})_i$
  est vérifiée~:
  \begin{align*}
    \widehat{g\circ h} &= f_\Sigma\circ (g \circ (h_i)) \circ
    (f_{\Sigma_1}^{-1},\ldots,f_{\Sigma_n}^{-1})\\
    &= f_\Sigma\circ g \circ (f_{\Gamma_i}^{-1}\circ f_{\Gamma_i}\circ h_i\circ
    (f_{\Sigma_1}^{-1},\ldots,f_{\Sigma_n}^{-1}))_i\\
    &= f_\Sigma\circ g \circ (f_{\Gamma_1}^{-1},\ldots,f_{\Gamma_p}^{-1})
    \circ (f_{\Gamma_i}\circ h_i\circ
    (f_{\Sigma_1}^{-1},\ldots,f_{\Sigma_n}^{-1}))_i\\
    &= \hat f \circ (\hat{g_i})_i
  \end{align*}
  la stabilité des fonctions RP par composition et l'hypothèse d'induction
  permettent donc de conclure.
\end{itemize}

On voit donc que le point réellement important de cette preuve est le cas de
la récursion primitive.

\begin{lemma}
  Soit $f$ une fonction RPG, alors $\hat f$ est une fonction RP.
\end{lemma}

\begin{proof}
  On procède par induction sur les fonctions RPG. On a prouvé juste avant les
  cas directs, on s'intéresse donc au cas de la récursion primitive.

  Soient des ensembles finis $\Sigma_1,\ldots,\Sigma_p,\Gamma,\Sigma$ et
  \[f : \left(\prod_{i = 1}^p (\Sigma_i)^\star\right)\to \Sigma^\star\qquad
  \forall a \in \Gamma, g_a : \left(\prod_{i = 1}^p
  (\Sigma_i)^\star\right)\times\Gamma^\star\times\Sigma^\star
  \to \Sigma^\star\]
  des fonctions RPG. On souhaite montrer que $\widehat{\rec(f,(g_a))}$ est
  une fonction RP sachant que $\hat f, (\hat{g_a})_{a\in \Gamma}$ sont
  des fonctions RP. On suppose que $\Sigma = \{0,\ldots,n-1\}$.

  On a vu comment extraire un élément de $\Sigma^\star$ à partir d'un
  entier. L'objectif dans cette construction va être d'adapter cette
  extraction pour l'appliquer directement à la récursion. Dans un premier
  temps, avec le même argument que dans celui pour construire $f_\Sigma$,
  on peut définir une fonction $\hat g$ telle que
  \[\hat g (x_1,\ldots,x_p,y,z) = \widehat{g_{z\% n}}(x_1,\ldots,x_p,y//n,z)\]
  en imbricant des instructions conditionnelles.

  On définit alors la fonction
  \[h(x_1,\ldots,x_p,x) \defeq
  \langle\pi'_1(x) // n,\hat g(x_1,\ldots,x_p,\pi'_1(x),\pi'_2(x))\rangle\]
  On rappelle que la fonction $d$, définie dans une preuve précédente, associe
  à $m$ la taille de $f_\Sigma^{-1}(m)$. On remarque l'identité suivante, pour
  tous $x_1,\ldots,x_p,y,z\in \mathbb N, u \in \Gamma^\star, a \in \Gamma$~:
  \[h(x_1,\ldots,x_p,y,\langle f_\Gamma(u\star a),z\rangle) =
  \langle f_\Gamma(u),g_a(x_1,\ldots,x_p,u,z)\rangle\]

  On définit alors la fonction $F$ à $p+2$ arguments suivante~:
  \[F \defeq
  \rec(\alpha\circ (\pi_{p+1}^{p+1},f\circ (\pi_1^{p+1},\ldots,\pi_{p+1}^{p+1})),
  h\circ (\pi_1^{p+3},\ldots,\pi_p^{p+3},\pi_{p+3}^{p+3}))\]
  Cette fonction va retourner des codes de couples. L'intérêt est de pouvoir
  utiliser l'appel récursif pour faire réduire l'argument autrement que d'un
  seul cran par un seul cran en stockant l'argument dans l'appel récursif,
  avec la valeur retournée. On montre donc d'abord par récurrence sur $k$ que
  pour tout $u = u_1\cdots u_N\in\Gamma^\star$,
  \[F(x_1,\ldots,x_p,f_\Gamma(u),k) = \langle f_\Gamma(u_1\cdots u_{N-k}),
  \widehat{\rec(f,(g_a))}(x_1,\ldots,x_p,f_\Gamma(u_N\cdots u_{N-k+1}))\rangle\]
  \begin{itemize}
  \item dans le cas où $k = 0$, les deux membres de l'équation sont
    effectivement égaux à
    $\langle f_\Gamma(u_1\cdots u_N),\hat f(x_1,\ldots,x_p)\rangle$.
  \item supposons que l'égalité est vraie pour $k$, alors
    \begin{align*}
      F(x_1,\ldots,x_p,f_\Gamma(u),k + 1) &=
      h(x_1,\ldots,x_p,F(x_1,\ldots,x_p,f_\Gamma(u),k))\\
      &= h(x_1,\ldots,x_p,\langle f_\Gamma(u_1\cdots u_{N-k}),\\
      &\widehat{\rec(f,(g_a))}(x_1,\ldots,x_p,f_\Gamma(u_N\cdots u_{N-k+1}))
      \rangle)\\
      &= \langle f_\Gamma(u_1\cdots u_{N-k-1}),\\
      &g_{u_{N-k}}(\widehat{\rec(f,(g_a))}(x_1,\ldots,x_p,
      f_\Gamma(u_N\cdots u_{N-k+1})))\\
      &= \langle f_\Gamma(u_1\cdots u_{N-k-1}),\\
      &\widehat{\rec(f,(g_a))}(x_1,\ldots,x_p,f_\Gamma(u_N\cdots u_{N-k}))
    \end{align*}
  \end{itemize}
  D'où le résultat par récurrence.

  On laisse en exercice le soin de vérifier qu'il est possible de transformer
  $f_\Gamma(u_N\cdots u_1)$ en $f_\Gamma(u_1\cdots u_N)$ par une fonction RP.
  En utilisant cette fonction, qu'on notera simplement $a \mapsto \overline a$,
  on construit la fonction~:
  \[G(x_1,\ldots,x_p,m) \defeq
  \pi'_2(F(x_1,\ldots,x_p,\overline m,d(m)))\]
  En utilisant l'identité précédente, on sait que
  \[G(x_1,\ldots,x_p,f_\Gamma(u)) =
  \widehat{\rec(f,(g_a))}(x_1,\ldots,x_p,f_\Gamma(u))\]
  d'où le résultat.

  Ainsi $\widehat{\rec(f,(g_a)_a)}$ est aussi une fonction RP, donc par
  induction sur les fonction RPG, pour toute fonction RPG $f$ la fonction
  $\hat f$ associée est RP.
\end{proof}

\begin{exercise}
  Vérifier que la fonction $a \mapsto \overline a$ est effectivement une
  fonction RP.
\end{exercise}

\begin{theorem}
  Soit une fonction $f : \mathbb N^n \to \mathbb N$. Cette fonction est
  RPG si et seulement si elle est RP.
\end{theorem}

\begin{proof}
  Il est clair que si $f$ est RP alors elle est RPG. Dans le sens réciproque,
  on sait que $\hat f$ est RP, donc
  \[\id\circ f \circ (\id,\ldots,\id) \in \RecP\]
  ce qui revient à dire que $f \in \RecP$, d'où le résultat.
\end{proof}

\begin{remark}
  Si nous avons jusque là donné des termes explicites, il doit être clair pour
  le lecteur que ces termes explicites sont de moins en moins lisibles, et les
  exemples précédents suffisent pour donner une idée fiable des manipulations
  autorisées dans le cadre des fonctions RP et RPG. Aussi, nous emploierons
  désormais des arguments moins formels, en essayant malgré tout d'être
  suffisamment précis pour ne pas oublier des subtilités techniques.
\end{remark}

Ainsi, les fonctions RPG n'apportent pas plus de puissance de calcul, puisque
les fonctions sur les entiers restent les mêmes. De plus, comme on possède un
codage bijectif bi-RPG entre chaque $\Sigma^\star$ et $\mathbb N$, on en conclut
que le pouvoir expressif de $\mathbb N$ est suffisant. L'utilité des fonctions
RPG est de permettre de facilement passer de fonctions sur des langages
algébriques à leur codage. Donnons d'abord un premier résultat important~: un
langage algébrique est une partie RPG.

\begin{proposition}
  Soit $\Sigma$ un alphabet et $G$ une grammaire hors contexte. Alors
  $\mathcal L_G$ est une partie de $\Sigma^\star$ dont l'indicatrice est
  une fonction RPG (à valeurs dans $\btwo$).
\end{proposition}

\begin{proof}
  Commençons par remarquer que si l'on prend une grammaire équivalente à
  $G$, alors $\mathcal L_G$ sera strictement la même fonction. Ainsi, on
  peut supposer que $G$ est une grammaire sous forme normale de Greibach
  quadratique. On sait alors que toute dérivation de taille $n$ depuis
  un symbole non terminal produit au moins un mot de taille $n$. Il
  nous suffit donc de lister tous les mots obtenus en $n$ dérivations
  depuis le symbole non terminal initial de la grammaire $G$, puis vérifier
  que le mot dont on cherche à tester l'appartenance apprait dans la liste
  des mots listés. Comme on sait qu'on peut encoder les mots par des entiers
  et les listes d'entiers par des entiers, il est clair qu'on peut manipuler
  les listes comme attendu. De plus, l'égalité entre entiers permet de
  déduire l'égalité entre mots au sens général, et ainsi le test d'appartenance.
\end{proof}

Cette proposition permet de donner du sens à la définition suivante.

\begin{definition}[Fonction RPG de langage]
  Soit $\Sigma,\Gamma$ deux alphabets et $\mathcal L \subseteq \Sigma^\star$ un
  langage RPG sur $\Sigma$. Une fonction $f : \mathcal L \to \Gamma^\star$
  est dite RPG s'il existe une fonction RPG
  $\tilde f : \Sigma^\star \to \Gamma^\star$ qui coïncide avec $f$ sur
  $\mathcal L$.
\end{definition}

\begin{remark}
  Nous décidons de contraindre $\mathcal L$ à être lui-même RPG car sinon,
  notre fonction $\tilde f$ n'aurait pas de raison de définir une fonction dont
  le domaine est $\mathcal L$~: appeler $\tilde f$ sur une valeur ne nous
  permet pas de savoir si l'application de la fonction était autorisée. Au
  contraire, s'il est possible d'avoir un processus préalable nous disant
  quelles valeurs peuvent être effectivement appelées, alors la fonction définie
  sur $\mathcal L$ est calculable par des fonctions RPG dans tous ses aspects.
\end{remark}

Un exemple essentiel de fonction RPG de langage est celui des fonctions
définies par inductions à partir de fonctions RPG.

\begin{proposition}
  Soit $\Sigma,\Gamma$ deux alphabets et $G$ une grammaire engendrant un
  automate à pile déterministe sur
  $\Sigma$. On suppose que pour toute règle $A \to u$ dans $G$, on dispose d'une
  fonction RPG $g_{A,u} : (\Gamma^\star)^n \to \Gamma^\star$ où $n$ est le nombre
  de non terminaux apparaissant dans $u$. Alors la fonction
  $g : \mathcal L_G \to \Gamma^\star$ donnée par la \cref{prop.PU.gram} est une
  fonction RPG.
\end{proposition}

\begin{proof}
  Comme $G$ engendre un automate à pile déterministe, cela signifie que pour
  un mot $u$ décomposable en $u = vwx$, si $A \to w$ est une règle de $G$ et
  que $u \in \mathcal L_G$ alors $S \to^\star vAx \to^\star vw$ est l'unique
  dérivation de $S$ à $u$ à l'ordre près des dérivations parallèles
  (cela se justifie par le calcul sur l'automate déterministe).

  On peut donc construire la fonction de la façon suivante~:
  \begin{itemize}
  \item on prend en entrée un mot $u$, et on parcourt les préfixes de $u$
    jusqu'à obtenir une décomposition $u = vwx$ où $A \to w$ est une règle
    de $G$ (bien sûr, $v$ et $x$ peuvent potentiellement être vides)
  \end{itemize}

  A FAIRE
\end{proof}

\begin{remark}
  De la même manière qu'on peut généraliser la \cref{prop.PU.gram} à des cas
  où les ensembles associés à chaque non terminal peuvent différer, cette
  proposition s'étend aussi à ces cas.

  Il est aussi possible de généraliser la proposition en l'appliquant à des
  grammaires non ambigües en général. Cependant, la preuve est plus complexe
  car l'algorithme pour trouver la dérivation menant au mot souhaité ne peut
  pas se contenter de considérer la première règle disponible (ce qui est le
  cas pour un langage déterministe).
\end{remark}

Ces résultats nous permettent donc de voir les langages algébriques comme une
sous-classe des langages RPG. On voit aussi que des opérations syntaxiques
simples sont RPG. Par exemple, étant donnée une signature du premier ordre
$\Delta$, un terme $t$ sur $\Delta$, une variable du premier ordre $x_n$ avec
$n \in \mathbb N$ et une formule $\varphi$ sur $\Delta$, il est possible de
définir la substitution $\varphi[t/x_n]$ par induction sur la grammaire des
formules sur $\Delta$~:
\begin{itemize}
\item on définit d'abord la substitution pour un terme $t'$. Si $t' = x_m$ où
  $m \neq n$, alors $t'[t/x_n] = t'$ ; si $t' = x_n$ alors $t'[t/x_n] = t$ et
  si $t' = f(t_1,\ldots,t_p)$ alors
  $t'[t/x_n] = f(t_1[t/x_n],\ldots,t_p[t/x_n])$.
\item si $\varphi = R(t_1,\ldots,t_p)$, alors
  $\varphi[t/x_n]=R(t_1[t/x_n],\ldots,t_p[t/x_n])$.
\item le cas de $\top$ et $\bot$ est simple~: la substitution ne fait rien.
\item dans le cas de $\lor,\land,\to$, on applique simplement la substitution
  récursivement aux sous-formules.
\item si $\varphi = \exists x,\psi$ (respectivement
  $\varphi = \forall x, \psi$), alors $\varphi[t/x_n] = \exists x, \psi[t/x_n]$
  (respectivement $\varphi[t/x_n] = \forall x, \psi[t/x_n]$).
\end{itemize}

En réalité, le cas des quantificateurs est un peu particulier. On peut se
demander comment est représentée une variable liée telle que le $x$ dans
$\exists x, \psi$. La façon la plus simple de faire est de considérer que
cette quantification lie $x_0$, et donc que la variable libre $x_0$ dans
$\exists x, \psi$ est la variable libre $x_s(x_0)$ dans $\psi$. Dans ce cas,
la définition récursive reste simple~:
$\varphi[t/x_n] = \exists x, \psi[t/x_{n+1}]$.

Malheureusement, toutes les fonctions qui peuvent s'exprimer par un algorithme
ne sont pas des fonctions RP. Comme on l'a dit au début, une fonction RP peut
se voir comme un programme impératif n'utilisant que la boucle \texttt{for}. La
boucle \texttt{while}, elle, permet de faire des itérations arbitrairement
grandes, sans savoir \latinexpr{a priori} si on aura un nombre fini
d'itérations. Cependant, dans l'autre sens, il est possible de définir la boucle
\texttt{while} à partir de la boucle \texttt{for}, dans les cas où la première
boucle converge. Si l'on décide d'écrire
\[\texttt{while}\;\varphi(x) \;\texttt{do}\; f ; x \coloneq x + 1\;
\texttt{done}\]
par exemple, pour appliquer une procédure $f$ pour tous les $x$ tels que
$\varphi(x)$, on peut tout aussi bien écrire, en fait,
\[\texttt{for}\; i = 0 \;\texttt{to}\; \mu(\lnot \varphi)\;\texttt{do}\; f\;
\texttt{done}\]
Ainsi, la minimisation non bornée nous permet de simuler les boucles
arbitrairement grandes.

Nous définissons donc une classe de fonctions plus générales, les fonctions
récursives (et récursives généralisées) en ajoutant cet opérateur. Plutôt que de
le présenter par minimisation d'un prédicat, on va le présenter à partir d'une
fonction, en considérant le prédicat \og la fonction s'annule en ce point\fg qui
ne fait pas perdre de généralité (puisqu'un prédicat RP est déjà une fonction
valant $0$ ou $1$).

\begin{definition}[Fonction récursive, récursive généralisée]
  On définit la classe $\Rec$ des fonctions récursives comme la plus petite
  classe de fonctions partielles contenant la classe $\RecP$ et telle que si
  $f : \mathbb N^{n+1} \to \mathbb N$ est une fonction récursive, alors
  c'est aussi le cas de la fonction
  \[\begin{array}{ccccc}
  \mu(f) & : & \mathbb N^n & \longrightarrow & \mathbb N\\
  & & (x_1,\ldots,x_n) &\longmapsto & \min \{y \in \mathbb N \mid
  f(x_1,\ldots,x_n,y) = 0\}
  \end{array}\]
  où la fonction $\mu(f)$ est indéfinie là où l'ensemble dont on prend le
  minimum est infini.

  La classe $\RecG$ des fonctions récursives généralisées est la plus petite
  classe de fonctions partielles contenant la classe $\RPG$ et telle que si
  \[f : \left(\prod_{i = 1}^n (\Sigma_i)^\star\right)
  \times \mathbb N \to \Sigma^\star\]
  est une fonction récursive généralisée, alors
  \[\begin{array}{ccccc}
  \mu(f) & : & \displaystyle\prod_{i = 1}^n (\Sigma_i)^\star &\longrightarrow &
  \mathbb N\\
  & & (u_1,\ldots,u_n) &\longmapsto &\min\{y \in \mathbb N \mid
  f(u_1,\ldots,u_n,y) = \varepsilon\}
  \end{array}\]
  est aussi une fonction récursive généralisée.
\end{definition}

\begin{exercise}
  Montrer que pour les fonctions $f : \mathbb N^n \to \mathbb N$, appartenir à
  $\Rec$ est équivalent à appartenir à $\RecG$.
\end{exercise}

La classe $\Rec$ est en fait la classe des fonctions calculables, au sens des
fonctions que l'on peut écrire comme des programmes informatiques. Dans la
section qui suit, on s'intéresse à un autre formalisme~: celui des machines de
Turing. Nous reviendrons à la classe $\Rec$ dans la dernière sous-section de la
section suivante, pour prouver son équivalence avec la classe que l'on définira
grâce aux machines de Turing.

\section{Machines de Turing}

Les machines de Turing, introduites dans \cite{turing1936a}, sont un formalisme
très proche de celui des automates. La différence principale est qu'au lieu
de lire linéairement un mot, comme dans le cas d'un automate fini ou d'un
automate à pile, une machine de Turing va agir sur un ruban de données. Cette
action permet d'avoir des calculs arbitrairement longs, et le ruban de données
est infiniment grand pour permettre d'effectuer des calculs aussi grands que
souhaité. L'action sur le ruban, elle, sera déterminée par une structure
quasiment identique à celle d'un automate~: à chaque instant, une tête de
lecture indique à quelle place sur le ruban on effectue l'action, et l'action
dépend de la lettre lue et de l'état de la machine. La différence principale est
que la machine peut alors décider de continuer la lecture (vers la droite) ou
bien de revenir en arrière (vers la gauche). Ce formalisme est un prototype de
langage impératif, qui agit sur une bande de mémoire selon un programme écrit à
l'avance.

Dans cette section, on définit le formalisme élémentaire pour traiter des
machines de Turing. Nous montrons ensuite que différents choix sont possibles
pour définir les machines de Turing~: utiliser plusieurs rubans, considérer des
états acceptant/rejetant, utiliser des machines non déterministes\ldots Enfin,
nous montrons que les fonctions calculables au sens des machines de Turing sont
équivalentes aux fonctions récursives.

\subsection{Premiers pas dans le formalisme des machines de Turing}

Donnons d'abord une définition simple de machine de Turing, permettant de plus
rapidement travailler avec.

\begin{definition}[Machine de Turing]
  Soit $\Sigma$ un alphabet. Une machine de Turing $M$ sur $\Sigma$ est la
  donnée de~:
  \begin{itemize}
  \item un ensemble fini $Q$ d'états
  \item un état initial $q_0$
  \item un ensemble d'états d'arrêt $F$
  \item un alphabet $\Gamma$ de travail, tel que $\Sigma \subseteq \Gamma$
  \item un symbole blanc $\square \in \Gamma$
  \item une fonction de transition partielle
    \[\delta : Q \times \Gamma \longrightarrow Q \times \Gamma \times
    \{\lhd,\rhd\}\]
  \end{itemize}

  On note $\TM(\Sigma)$ (pour \foreignexpr{Turing machine}) l'ensemble des
  machines de Turing sur $\Sigma$.
\end{definition}

Décrivons le fonctionnement d'une machine de Turing à partir de ses
composantes~:
\begin{itemize}
\item la machine de Turing va agir sur un ruban qui est une suite de symboles
  de $\Gamma$ de la forme $u\square^\infty$, c'est-à-dire ayant un nombre
  fini d'élément différents de $\square$. A chaque étape, la machine pointe à
  un certain indice du ruban, lit le symbole à cet indice et agit en
  conséquence.
\item au début de l'exécution, la machine point à l'incide $0$ et est dans
  l'état $q_0$.
\item à chaque étape lors de l'exécution, en supposant que le ruban est de la
  forme $uav\square^\infty$ et que la machine pointe sur le symbole $a$, la
  machine étant en un état $q$, on regarde $\delta(q,a) = q',b,m$~: le symbole
  $a$ est remplacé par le symbole $b$, la machine entre dans l'état b et elle
  décale sa tête de lecture d'une case vers la gauche si $m = \lhd$, vers la
  droite si $m = \rhd$.
\item lorsque la machine entre dans un état $q \in F$, l'exécution s'arrête.
\end{itemize}

A FAIRE : SCHEMA DE LA SITUATION EN TIKZ

Rendons maintenant ce fonctionnement formel. On définit d'abord la notion de
configuration, qui est un objet permettant de retenir simultanément l'état d'une
machine, de son ruban et l'emplacement de sa tête de lecture.

\begin{definition}[Configuration d'une machine sur un ruban]
  Soit une machine de Turing $M$ sur un alphabet $\Sigma$. Une configuration
  pour $M$ est une suite $u \in (\Gamma\cup Q)^\mathbb N$ telle que~:
  \begin{itemize}
  \item toutes les valeurs de $u$ sauf un nombre fini sont $\square$
  \item il existe exactement un indice $i$ tel que $u_i \in Q$.
  \end{itemize}
  Etant donnée une configuration $u$, on appel état de $M$ en $u$ l'unique
  valeur $q \in Q$ prise par $u$.
\end{definition}

\begin{notation}
  On notera une configuration $uqv\square^\infty$ pour indiquer que
  $u \in \Gamma^\star$, $v \in \Gamma^\star$ et $q \in Q$.
\end{notation}

Il faut lire la configuration $uqv\square^\infty$ comme le fait que la tête
de lecture de la machine se trouve à la première lettre de $v$, dans l'état $q$,
et que tous les symboles différents de $\square$ sont contenus dans $uv$.

Une machine de Turing agit alors naturellement sur les configurations grâce à sa
fonction de transition.

\begin{definition}[Action d'une machine sur une configuration]
  Soit $M$ une machine de Turing sur un alphabet $\Sigma$ et
  $uqav\square^\infty$ une configuration pour $M$
  (où $u,v \in \Gamma^\star, a\in \Gamma$ et $q \in Q$). Soit
  $q',b,m \defeq \delta(q,a)$, on définit l'action de $M$ en un pas sur
  $uqbv\square^\infty$, par
  \[
  M\cdot uqav\square^\infty \defeq
  \begin{cases}
    u'q'a'bv\square^\infty\text{ si } m = \lhd\text{ et si } u = u'\star a'\\
    ubq'v\square^\infty\text{ si } m = \rhd \\
    \text{indéfini sinon}
  \end{cases}\]
\end{definition}

\begin{remark}
  Si $\delta$ n'est pas définie en un certain couple $a,q$, l'action n'est pas
  définie non plus, comme l'indique l'impossibilité de décomposer $\delta(q,a)$.
\end{remark}

Cette action sur les configurations représente ce qu'il se déroule lors de
l'exécution de $M$ pendant une seule unité de temps de calcul. Il nous faut
ensuite, bien sûr, itérer cette action pour créer un vrai calcul de la part de
$M$. Comme dans le cas des automates, on va appeler trace d'un calcul la suite
des configurations parcourues.

\begin{definition}[Trace d'une exécution d'une machine de Turing]
  Soit une machine de Turing $M$ sur un alphabet $\Sigma$ et
  $uqv\square^\infty$ une configuration pour $M$. On appelle trace de
  l'exécution de $M$ sur $uqv\square^\infty$ la plus grande suite finie ou
  infinie de configurations $p_0,\ldots,p_i,\ldots$ telle que
  \begin{itemize}
  \item $p_0 = uqv\square^\infty$
  \item pour tout $i$, $p_{i+1} = M\cdot p_i$
  \item s'il existe $p_i$ tel que l'état de $M$ en $p_i$ appartient à $F$,
    alors la trace n'est pas définie pour $j > i$
  \end{itemize}

  Pour tout mot $u \in \Sigma^\star$, on appelle trace de l'exécution de $M$
  la trace de l'exécution de $M$ sur $q_0u\square^\infty$.
\end{definition}

L'exécution d'une machine sur un mot $u$ peut ainsi mener à plusieurs cas~:
\begin{itemize}
\item la trace est infinie, ce qui correspond à un calcul qui ne se termine pas,
  tel un programme exécutant une boucle de la forme \texttt{while true} ;
\item la trace est finie mais ne contient pas d'état d'arrêt, ce qui correspond
  à une dernière configuration pour laquelle l'action de $M$ est indéfinie ;
\item la trace est finie et contient un état d'arrêt, ce qui correspond à un
  calcul qui s'exécute correctement et s'arrête~: le ruban dans la configuration
  finale est alors de la forme $vw\square^\infty$ où $v \in \Sigma^\star$ et
  $w \in \Gamma^\star$ ($v$ peut être vide, et $w$ contient potentiellement
  des lettres dans $\Sigma)$. On a alors associé à $u\in\Sigma^\star$ un mot
  $v \in \Sigma^\star$. On notera dans la suite $M(u)$ ce mot $v$.
\end{itemize}

Une machine de Turing définit donc une fonction partielle
$\Sigma^\star \partialto \Sigma^\star$~: on dira que cette fonction est calculée
par la machine de Turing considérée, ce qui nous mène à la notion de fonction
calculable.

\begin{definition}[Fonction calculée par une machine de Turing]
  Soit $M$ une machine de Turing sur un alphabet $\Sigma$. On définit la
  fonction partielle calculée par $M$ comme~:
  \[\begin{array}{ccccc}
  f_M & : & \Sigma^\star & \longrightarrow & \Sigma^\star\\
  & & u & \longmapsto & M(u)
  \end{array}\]
  où $M(u)$ est indéfini si la trace de l'exécution de $M$ sur $u$ est infinie
  ou ne se termine pas sur un état d'arrêt.
  
  On définit la classe des fonctions calculables sur $\Sigma$ comme
  \[\Calc(\Sigma)\defeq \{ f_M\mid M \in \TM(\Sigma)\}\]
\end{definition}

\subsection{\'Equivalence de machines de Turing}

\subsection{\'Equivalence avec les fonctions récursives}

Pour montrer que les fonctions calculables sont équivalentes aux fonctions
récursives généralisées, deux sens sont à faire~: montrer qu'il est possible
d'écrire une machine de Turing qui calcule une fonction $\RecG$, et montrer
qu'il est possible de simuler l'exécution d'une machine de Turing par une
fonction $\RecG$.

Le premier sens demande de raisonner par induction~: on montre que les
constructions définissant la classe $\RecG$ peuvent se faire avec des machines
de Turing. Le sens réciproque, lui, va se faire en deux temps. Tout d'abord, on
prouve qu'il existe deux fonctions $T,U \in \RPG$ qui, étant donnés un code
$e$ donnant la description d'une machine de Turing $M$, une entrée $x$ et un
temps $t$, retourne respectivement si la machine de Turing s'est arrêtée en
moins de $t$ étapes de calcul sur l'entrée $x$ et l'état du ruban après
l'exécution de $M$ sur $x$ pendant $t$ étapes de calcul. En utilisant alors la
minimisation non bornée, on obtient une simulation des machines de Turing par
les fonctions $\RecG$, et on remarque alors qu'une fonction $\RecG$ ne
nécessite qu'une utilisation de la minimisation non bornée par rapport à une
fonctions $\RPG$.

On montre d'abord le sens direct.

\begin{lemma}
  Pour toute fonction récursive généralisée $f$, il existe une machine de
  Turing telle que $f_M = f$.
\end{lemma}

\begin{proof}
  A FAIRE
\end{proof}

Pour montrer le sens réciproque, on doit d'abord décider d'une façon de coder
une machine de Turing $M$ sur un alphabet $\Sigma$ par un mot. Comme le nom des
états d'une machine ne sont pas en eux-mêmes importants, on peut remplacer
l'ensemble $Q$ par un entier $n$ indiquant le nombre d'états. Quitte à n'avoir
qu'un état initial et qu'un état d'arrêt, on peut considérer que
$Q = \{0,\ldots,n-1\}$, que $0$ est l'état initial et $n-1$ est l'état final.
Pour l'alphabet de bande, on peut construire un nouvel alphabet de bande en
considérant deux symboles $\alpha, \beta \notin \Sigma$. Si
$\Gamma = \Sigma \sqcup \{\square\}\sqcup \Sigma'$ et
$\Sigma' = \{a_1,\ldots,a_m\}$, alors on peut coder $a_i$ par $\alpha^i\beta$
et $\square$ par $\beta$. Ainsi, on peut retenir uniquement l'entier $m$ et
travailler sur l'alphabet $\Sigma\cup \{\alpha,\beta\}$. La fonction de
transition, elle, va s'encoder de façon plus technique. On a ainsi un codage
d'une machine de Turing sur $\Sigma$. Le mot associé doit pouvoir exprimer les
symboles de $\Gamma$, donc s'écrire au moins sur $\Sigma\cup\{\alpha,\beta\}$.
Il doit aussi permettre d'écrire des nombres pour exprimer $n$ et $m$. On
comptera $n$ et $m$ par $\alpha^n$ et $\alpha^m$ respectivement, en mettant
un symbole $\beta$ pour séparer ces deux nombres.

\begin{definition}[Codage d'une fonction de transition]
  Soit $\Sigma$ un alphabet, $\alpha,\beta\notin\Sigma$, $\delta$ la fonction de
  transition d'une machine de Turing sur $\Sigma$ à $n$ états et d'alphabet de
  bande
  $\Gamma = \Sigma\sqcup\{\square\}\sqcup\{a_1,\ldots,a_p\}$. On définit le
  code de sa fonction de transition
  $\langle\delta\rangle\in(\Sigma\cup\{\alpha,\beta\})^\star$ par
  \[\langle\delta\rangle\defeq\]
\end{definition}

\begin{definition}[Codage d'une machine de Turing]
  Soit $\Sigma$ un alphabet, et $\alpha,\beta\notin \Sigma$. On définit le code
  d'une machine de Turing $M = (Q,q_0,q_a,\Gamma,\square,\delta)$ comme le mot
  sur $\Sigma\cup\{\alpha,\beta\}$ suivant~:
  \[\langle M\rangle \defeq \alpha^{|Q|}\beta\alpha^{|\Gamma\setminus \Sigma|}\beta
  \]
\end{definition}
