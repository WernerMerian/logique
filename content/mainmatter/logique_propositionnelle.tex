\chapter{Logique propositionnelle}
\label{chp.logprop}

\minitoc

\lettrine{P}{our} commencer l'étude de la logique, nous allons étudier sa forme
la plus élémentaire~: la logique propositionnelle. Lorsque l'on écrit une phrase
mathématique, disons par exemple
\[\forall n \in \mathbb N, (\exists m \in \mathbb N, n = 2\times m) \text{ ou }
(\exists m \in \mathbb N, n = 2 \times m + 1)\]
on peut séparer plusieurs parties~:
\begin{itemize}
\item les quantificateurs.
\item les connecteurs logiques, comme \og et\fg{}, \og ou\fg{} ou \og non\fg{}.
\item les propositions atomiques, comme $n = 2 \times m$ ci-dessus.
\end{itemize}

La logique propositionnelle est une simplification de cette grammaire, dans
laquelle les propositions atomiques sont remplacées par de simples variables,
pouvant prendre la valeur $\mathrm{Vrai}$ ou $\mathrm{Faux}$, et où l'on
supprime les quantificateurs. L'étude de la logique propositionnelle, beaucoup
plus simple que le calcul des prédicats, permet de donner une première idée des
propriétés qui nous intéressent dans la logique.

\section{Définitions}

Fixons tout d'abord un ensemble $\Var$ dénombrable de variables
propositionnelles. Nous allons construire l'ensemble des propositions comme un
ensemble inductif, en ajoutant les connecteurs logiques usuels.

\begin{definition}[Propositions]
  On définit l'ensemble $\Prop$ des propositions du calcul
  propositionnel par la grammaire suivante~:
  \[P,Q ::= x \mid \top \mid \bot \mid \lnot P \mid P \lor Q \mid P \land Q
  \mid P \to Q\]
  où $x\in \Var$ est une variable propositionnelle.
\end{definition}

Le sens des différents symboles est le suivant~:
\begin{itemize}
\item $\top$ représente la proposition vraie.
\item $\bot$ représente la proposition fausse.
\item $\lnot$ représente la négation logique.
\item $\lor$ représente la disjonction logique.
\item $\land$ représente la conjonction logique.
\item $\to$ représente l'implication logique.
\end{itemize}

Par convention, nous donnons l'ordre de priorité (du plus prioritaire au moins
prioritaire) suivant~: $\lnot > \land > \lor > \to$. Cette convention évite
ainsi d'écrire certaines parenthèses. De plus, comme $\land$ et $\lor$ seront
montrés associatifs, nous ne parenthèserons pas $P\lor Q\lor R$ par exemple.
Pour $\to$, nous associons à droite, c'est-à-dire que $P\to Q\to R$ signifie
$P\to (Q \to R)$. Par exemple la proposition
\[(P \to Q)\land (R \to Q) \to P\lor R \to Q\] doit se lire
\[((P \to Q) \land (R \to Q)) \to ((P \lor R) \to Q)\]

L'objectif d'une proposition est bien sûr de lui attribuer une valeur de vérité.
\'Evidemment, la valeur de vérité d'une proposition dépend de celle des variables.
Par exemple, $(x\lor \lnot y) \land z$ n'aura pas la même valeur de vérité
suivant si $z$ est vrai ou faux.

Pour manipuler les variables d'une propositions, il est important de définir
l'ensemble des variables impliquées dans la construction d'une proposition.

\begin{definition}[Variables libres]
  Par induction sur la structure inductive de $\Prop$, on définit pour
  $P$ l'ensemble $\VL(P)$ des variables libres de $P$~:
  \begin{itemize}
  \item si $P = x$ et $x\in\Var$, alors $\VL(P) = \{x\}$.
  \item si $P = \lnot Q$ alors $\VL(P) = \VL(Q)$.
  \item si $P = Q \lor R$ ou $P = Q \land R$ ou $P = Q \to R$,
    alors $\VL(P) = \VL(Q)\cup\VL(R)$.
  \end{itemize}
\end{definition}

\begin{remark}
  La dénomination de variable \og libre\fg{} prendra son sens dans le prochain
  chapitre. L'intérêt de définir $\VL$ et non juste l'ensemble des variables est
  d'ignorer les variables muettes, mais dans le calcul propositionnel aucune
  variable n'est muette.
\end{remark}

Une attribution de valeurs de vérité aux variables propositionnelles est appelée
un environnement. On utilisera l'ensemble $\{0,1\}$ pour signifier
$\{\mathrm{Faux},\mathrm{Vrai}\}$.

\begin{definition}[Environnement]
  Un environnement est une fonction partielle $\rho : \Var \to \{0,1\}$
  dont le domaine (l'ensemble des valeurs $x\in \Var$ sur lesquelles
  $\rho$ est défini) est fini.
\end{definition}

Un environnement permet ensuite de définir la notion de valuation, qui est la
valeur de vérité d'une proposition dans un environnement donné. On peut voir
la valuation comme le prolongement d'un environnement par les règles inductives
naturelles pour donner le sens voulu aux propositions.

\begin{definition}[Valuation]
  Soit $\rho$ un environnement. On définit par induction sur $\mathrm{Prop}$
  la fonction partielle $\Val_\rho : \Prop \to \{0,1\}$~:
  \begin{itemize}
  \item $\Val_\rho(\top) = 1$.
  \item $\Val_\rho(\bot) = 0$.
  \item pour $x\in \Var$, si $x\in \dom(\rho)$ alors
    $\Val_\rho (x)= \rho(x)$, si $x\notin \dom(\rho)$ alors
    $\Val_\rho (x)$ n'est pas défini.
  \item soit $P$ une proposition, alors
    $\Val_\rho(\lnot P) = 1 - \Val_\rho(P)$.
  \item soient $P$ et $Q$ deux propositions, alors
    $\Val_\rho(P\lor Q)=\max(\Val_\rho(P),\Val_\rho(Q))$
  \item soient $P$ et $Q$ deux propositions, alors
    $\Val_\rho(P\land Q)=\min(\Val_\rho(P),\Val_\rho(Q))$
  \item soient $P$ et $Q$ deux propositions, alors
    $\Val_\rho(P\to Q) = \max(1 - \Val_\rho(P),\Val_\rho(Q))$
  \end{itemize}
\end{definition}

\begin{exercise}
  Soit $\rho$ un environnement et $P$ une proposition, montrer que
  $\Val_\rho(P)$ est définie si et seulement si
  $\VL(P)\subseteq \dom(\rho)$.
\end{exercise}

\begin{exercise}\label{exo.val.VL}
  Soit $P$ une proposition. Soient $\rho$ et $\rho'$ deux environnements tels
  que $\rho_{|\;\VL(P)}=\rho'_{|\;\VL(P)}$. Montrer que
  $\Val_\rho(P)=\Val_{\rho'}(P)$.
\end{exercise}

On peut donc définir la relation de vérité, dans un environnement donné, pour
une proposition.

\begin{definition}[Satisfaction]
  Soit $\rho$ un environnement et $P\in\Prop$. On définit la relation
  $\rho\models P$ par $$(\rho\models P) \defeq (\Val_\rho(P) = 1)$$
  On dit alors que $\rho$ satisfait $P$.

  Si pour tout environnement $\rho$ tel que $\VL(P)\subseteq\dom(\rho)$,
  $\rho\models P$, alors on dit que $P$ est une tautologie, et on le note
  $\models P$. Si aucun environnement ne satisfait $P$, on dit alors que $P$ est
  une antilogie.
\end{definition}

\begin{exercise}
  Montrer que $P$ est une antilogie si et seulement si $\lnot P$ est une
  tautologie. En déduire que $P$ est une tautologie si et seulement si $\lnot P$
  est une antilogie.
\end{exercise}

Donnons un premier outil pour traiter des vérités du calcul des propositions~:
les tables de vérité.

\begin{definition}[Table de vérité]
  Une table de vérité pour une proposition $P$ de variables libres
  $x_1,\ldots,x_n$ est un tableau contenant $2^n$ lignes et $n+1$ colonnes, où
  chaque ligne énumère un environnement différent, où la
  \ordinalnumeralfeminin{$i$} colonne représente la valeur des environnement en
  $x_i$ et où la dernière colonne représente la valuation de $P$ pour
  l'environnement donné.
\end{definition}

\begin{example}
  Voici une table de vérité pour les expressions
  $x_0\lor x_1, \lnot (x_0\lor x_1), \lnot x_0\land \lnot x_1$ et
  $\lnot (x_0 \lor x_1)\to \lnot x_0 \land \lnot x_1$~:
  \begin{center}
    \begin{tabular}{|c|c|c|c|c|c|}
      \hline $x_0$ & $x_1$ & $x_0\lor x_1$ & $\lnot (x_0\lor x_1)$ &
      $\lnot x_0 \land \lnot x_1$ &
      $\lnot (x_0 \lor x_1)\to \lnot x_0 \land \lnot x_1$\\
      \hline $0$ & $0$ & $0$ & $1$ & $1$ & $1$ \\
      \hline $1$ & $0$ & $1$ & $0$ & $0$ & $1$ \\
      \hline $0$ & $1$ & $1$ & $0$ & $0$ & $1$ \\
      \hline $1$ & $1$ & $1$ & $0$ & $0$ & $1$ \\
      \hline
    \end{tabular}
  \end{center}
\end{example}

Une table de vérité permet de vérifier qu'une proposition est bien une
tautologie puisque, grâce à l'\cref{exo.val.VL}, nous savons que tout
environnement $\rho$ contenant les variable libres d'une proposition $P$ donnée
ne définit $\Val_\rho(P)$ que sur les variables libres listées dans la table de
vérité. Ainsi, une proposition est une tautologie si et seulement si toute la
dernière colonne est remplie de $1$.

\begin{exercise}
  Montrer que $\lnot x_0\land \lnot x_1 \to \lnot (x_0\lor x_1)$ est une
  tautologie.
\end{exercise}

La notion de tautologie peut être considérée comme la bonne notion de vérité
dans le cadre du calcul propositionnel~: une proposition vraie est une
proposition qui s'évalue toujours en une formule vraie. Comme $\to$ sert à
signifier l'implication logique, dire que $A \to B$ est une tautologie revient à
dire que chaque fois que $A$ est vraie, $B$ l'est aussi. Ainsi, en notant
$A \leftrightarrow B$ pour $(A \to B) \land (B \to A)$, dire que
$A \leftrightarrow B$ est une tautologie revient à dire que $A$ et $B$ prennent
toujours la même valeur de vérité. Cette relation est l'équivalence logique~:
elle traduit que deux propositions ont la même valeur.

\begin{definition}[\'Equivalence logique]
  Pour tous $P,Q\in\Prop$, on dit que $P$ et $Q$ sont logiquement équivalents,
  ce que l'on écrit $P\equiv Q$, si $\models P \leftrightarrow Q$.
\end{definition}

Un affaiblissement est la relation de conséquence logique.

\begin{definition}[Conséquence logique]
  Pour tous $P,Q\in\Prop$, on dit que $Q$ est conséquence logique de $P$, ce que
  l'on note $P\vDash Q$, si $\models P\to Q$.
\end{definition}

\begin{exercise}
  Vérifier à l'aide de tables de vérités les équivalences suivantes (appelées
  lois de De Morgan)~:
  \begin{align*}
    \lnot\lnot x &\equiv x\\
    \lnot (x \land y) &\equiv \lnot x \lor \lnot y\\
    \lnot (x \lor y) &\equiv \lnot x \land \lnot y
  \end{align*}
\end{exercise}

\section[Séquents propositionnels]{Calcul des séquents propositionnels et
  complétude}

Maintenant que nous avons défini une notion satisfaisante de vérité pour une
proposition, il convient de se demander quels outils permettent de l'établir.
Pour l'instant, pour prouver qu'une proposition est une tautologie, la seule
façon de procéder est d'en construire la table de vérité. C'est une façon
largement inefficace, puisqu'elle prend une taille exponentielle en le nombre de
variables libres d'une proposition, et la preuve qu'une proposition est une
tautologie est assez vide de sens~: dans l'exercice précédent, il n'a été
question que de calcul et pas de considérations logiques.

\subsection{Théorème de compacité}

Cette sous-section se concentre sur un théorème important de la logique~: le
théorème de compacité. Son principe est de permettre de passer d'ensembles finis
à des ensembles infinis. Si son utilité est relativement anecdotique dans le cas
de la logique propositionnelle, il sera un élément essentiel en logique du
premier ordre. Pour pouvoir établir ce théorème, nous devons tout d'abord
généraliser la relation de satisfaction $\vDash$ au cas d'un ensemble infini de
propositions.

\begin{definition}[Environnement infini]
  On définit l'ensemble $\mathcal E$ des environnement potentiellement infinis
  comme l'ensemble des fonctions partielles $\Var \to \{0,1\}$. On définit la
  fonction $\Val : \mathcal E\times \Prop \to \{0,1\}$, pour tout
  $\rho\in\mathcal E$, par :
  \[\Val_\rho(P) = \Val_{\rho_{|\VL(P)}}(P)\]
  où le deuxième $\Val$ correspond à la définition sur les environnements finis.

  On définit $\rho\models P$ de façon analogue à précédemment~:
  \[\rho\models P \defeq \Val_\rho(P) = 1\]
\end{definition}

\begin{exercise}
  Montrer que si $\rho$ est un environnement fini, alors les deux définitions de
  $\Val_\rho$ coïncident.
\end{exercise}

\begin{definition}[Satisfaction infinie]
  Soit $\mathcal P$ un ensemble (potentiellement infini) de propositions et
  $P\in\Prop$. On définit $\mathcal P\vDash P$ par
  \[\forall \rho\in\mathcal E, (\forall Q \in\mathcal P, \rho\models Q)
  \implies \rho\models P\]
\end{definition}

Le théorème de compacité possède plusieurs expressions différentes. Pour les
donner, nous allons introduire le vocabulaire nécessaire sur les ensembles
(potentiellement infinis) de propositions.

\begin{definition}[Satisfiabilité]
  On dit qu'un ensemble $\mathcal P\subseteq\Prop$ est satisfiable s'il existe
  $\rho\in\mathcal E$ telle que $\forall P\in\mathcal P, \rho\models P$. On dit
  qu'un ensemble $\mathcal P\subseteq\Prop$ est finiment satisfiable si toutes
  ses parties finies sont satisfiables.
\end{definition}

\begin{definition}[Contradiction]
  On dit qu'un ensemble $\mathcal P\subseteq\Prop$ est contradictoire s'il
  n'existe pas d'environnement $\rho\in\mathcal E$ tel que
  $\forall P \in\mathcal P, \rho\models P$. Un ensemble
  $\mathcal P\subseteq \Prop$ est finiment contradictoire si l'une de ses
  parties finies est contradictoire.
\end{definition}

Le théorème de compacité énonce alors l'équivalence entre la version finie et la
version infinie des deux caractères, et de façon équivalente, l'équivalence de
la relation $\vDash$ pour un ensemble infini et pour ses parties finies.
Montrons d'abord que ces trois principes sont bien équivalents.

\begin{proposition}
  Les trois propriétés suivantes sont équivalentes~:
  \begin{enumerate}[label=(\roman*)]
  \item\label{enum.compac.prop1} pour tout $\mathcal P\subseteq \Prop$,
    $\mathcal P$ est satisfiable si et seulement s'il est finiment satisfiable.
  \item\label{enum.compac.prop2} pour tout $\mathcal P\subseteq\Prop$,
    $\mathcal P$ est contradictoire si et seulement s'il est finiment
    contradictoire.
  \item\label{enum.compac.prop3} pour tout $\mathcal P\subseteq\Prop$ et
    $P\in\Prop$, $\mathcal P\vDash P$ si et seulement s'il existe
    $F\subfin \mathcal P$ tel que $F\vDash P$.
  \end{enumerate}
\end{proposition}

\begin{proof}
  Pour commencer, remarquons qu'un ensemble satisfiable est finiment
  satisfiable, qu'un ensemble finiment contradictoire est contradictoire, et que
  s'il existe $F\subfin \mathcal P$ tel que $F\vDash P$, alors pour tout
  environnement $\rho$ tel que $\rho\models \mathcal P$, on a en particulier
  $\rho\models F$ et donc $\rho\models P$. Il nous suffit donc de travailler sur
  un seul sens de l'équivalence à chaque fois. Nous allons maintenant montrer
  $\ref{enum.compac.prop1}\implies\ref{enum.compac.prop2}\implies
  \ref{enum.compac.prop3}\implies\ref{enum.compac.prop1}$~:
  \begin{itemize}
  \item Supposons \ref{enum.compac.prop1} et montrons \ref{enum.compac.prop2}.
    Soit $\mathcal P\subset \Prop$ contradictoire, montrons que $\mathcal P$
    est finiment contradictoire. Par l'absurde, supposons que $\mathcal P$ n'est
    pas finiment contradictoire~: toute partie finie $F\subseteq \mathcal P$
    possède donc une valuation $\rho_F$ telle que $\rho_F\models F$. Mais alors,
    en utilisant \ref{enum.compac.prop1}, on en déduit qu'il existe une
    valuation $\rho\models \mathcal P$. Pourtant $\mathcal P$ est
    contradictoire~: c'est une absurdité. Ainsi, par l'absurde, on en déduit que
    $\mathcal P$ est finiment contradictoire.
  \item Supposons \ref{enum.compac.prop2} et montrons \ref{enum.compac.prop3}.
    Soient $\mathcal P\subseteq\Prop, P\in\Prop$ tels que $\mathcal P\vDash P$.
    Montrons qu'il existe $F\subfin\mathcal P$, tel que $F\vDash P$. Comme
    $\mathcal P\vDash P$, on en déduit que $\mathcal P \cup \{\lnot P\}$ est
    contradictoire. Ainsi, par \ref{enum.compac.prop2}, on trouve un ensemble
    $F\subfin \mathcal P \cup \{\lnot P\}$ contradictoire. Deux choix se
    présentent alors~:
    \begin{itemize}
    \item si $F$ ne contient pas $\lnot P$, alors $F\subfin \mathcal P$, donc
      il n'existe pas de valuation telle que $\rho\models F$, ce qui signifie
      que toute valuation $\rho$ telle que $\rho\models F$ vérifie
      $\rho\models P$, donc $F\vDash P$.
    \item si $F$ contient $\lnot P$, alors on peut réécrire $F$ comme
      $F = F'\sqcup\{\lnot P\}$, où $F'\subfin \mathcal P$. Comme cet ensemble
      est contradictoire, cela signifie que pour toute valuation $\rho$ telle
      que $\rho\models F'$, on a $\rho\not\models \lnot P$ (car sinon cette
      valuation serait une valuation de $F$, ce qui n'existe pas). Or,
      $\rho\not\models \lnot P$ signifie que $\rho\models P$, donc toute
      valuation $\rho\models F'$ vérifie $\rho\models P$. On a donc trouvé
      $F'\subfin \mathcal P$ telle que $F'\vDash P$.
    \end{itemize}
    Dans les deux cas, on a trouvé $F\subfin \mathcal P$ telle que $F\vDash P$.
  \item Supposons \ref{enum.compac.prop3} et montrons \ref{enum.compac.prop1}.
    Soit $\mathcal P\subseteq\Prop$ un ensemble finiment satisfiable, montrons
    que $\mathcal P$ est satisfiable. Par l'absurde, supposons que $\mathcal P$
    n'est pas satisfiable. Cela signifie que $\mathcal P\vDash \bot$~: par
    \ref{enum.compac.prop3} on trouve donc $F\subfin \mathcal P$ tel que
    $F\vDash \bot$, $F$ est donc finiment contradictoire, ce qui contredit le
    fait que $\mathcal P$ est finiment satisfiable. Par l'absurde, on en déduit
    que $\mathcal P$ est satisfiable.
  \end{itemize}

  Les propositions sont ainsi toutes équivalentes.
\end{proof}

Il ne nous reste plus qu'à prouver le résultat en lui-même.

\begin{theorem}[Compacité de la logique propositionnelle]\label{thm.compac.prop}
  Pour tout $\mathcal P\subseteq\Prop$, si $\mathcal P$ est finiment satisfiable
  alors $\mathcal P$ est satisfiable.
\end{theorem}

\begin{proof}
  Soit $\mathcal P\subseteq\Prop$ finiment satisfiable, prouvons que
  $\mathcal P$ est satisfiable. Pour construire une valuation satisfaisant
  $\mathcal P$ entièrement, nous allons construire des valuations partielles
  sur les premières variables seulement. On construit donc une suite de
  valuations partielles $(\rho_n)_{n\in\mathbb N}$ chacune définie uniquement
  sur les variables $0$ à $n-1$, de telle sorte que pour tous $i\leq j$,
  $\rho_j(k) = \rho_i(k)$ pour tout $k < i$. De plus, on veut vérifier qu'à
  chaque $\rho_n$, il existe une infinité de valuations partielles
  $\rho'$ définies sur $k > n$ premières variables, étendant $\rho_n$ et
  pouvant s'étendre en une valuation totale $\rho''$ telle que
  $\rho''\models P_0,\ldots,P_k$. On raisonne donc par récursion~:
  \begin{itemize}
  \item à $0$, on considère simplement la fonction vide, définie nulle part.
    Pour vérifier la condition sur les extensions, on considère $k\in\mathbb N$.
    Comme $\mathcal P$ est finiment satisfiable, alors on peut trouver une
    valuation $\rho\models P_0,\ldots,P_{k-1}$~: on a donc une infinité de
    telles valuations partielles.
  \item supposons construite la valuation $\rho_n$, vérifiant les hypothèses
    énoncées plus haut. Dans l'infinité de $\rho'$ étendant $\rho_n$, il y en a
    une infinité valant $0$ en $n$, ou une infinité valant $1$ en $n$. Dans le
    premier cas, on peut construire $\rho_{n+1}$ en valant $\rho_n$ sur
    $\{0,\ldots,n-1\}$ et $0$ en $n$. Dans le second cas, on étend $\rho_{n+1}$
    en associant $1$ à $n$. Dans les deux cas, l'hypothèse est encore vérifiée.
  \end{itemize}
  On a donc construit une valuation $\rho$ comme la limite de ces valuations
  partielles (une version plus formelle de cet argument serait de considérer
  pour chaque $\rho_n$ l'ensemble
  $\{\rho : \Var \to \{0,1\}\mid \forall i < n, \rho(i) = \rho_n(i)\}$ et de
  prendre $\rho$ dans l'intersection de tous ces ensembles). Soit
  $P\in\mathcal P$, par définition $P$ n'utilise qu'un nombre fini de variables,
  dont un indice maximal qu'on notera $i$~: pour toute valuation $\rho'$
  coïncidant avec $\rho$ jusqu'à $i$, $\rho'\models P$ si et seulement si
  $\rho\models P$. Disons que $P = P_j$ dans notre énumération, et soit
  $n = \max(i,j)$~: alors il existe une valuation étendant $\rho_n$ et
  vérifiant $P$, et toute autre valuation coïncidant avec elle jusqu'à $n$
  vérifie $P$. C'est le cas de $\rho$, qui coïncide jusqu'à $n$ avec $\rho_n$ et
  donc avec toute extension de $\rho_n$, donc $\rho\models P$.

  Ainsi on a construit $\rho$ telle que
  \[\forall P \in\mathcal P, \rho\models P\]
  donc $\mathcal P$ est satisfiable.
\end{proof}

\subsection{Calcul des séquents}

Ce qui manque à notre système, c'est une syntaxe~: un système simple qui va nous
permettre de justifier des tautologies. Cette syntaxe se base sur la notion de
séquent~: un séquent est une paire de listes de propositions, que l'on écrira
$\Gamma\vdash \Delta$, exprimant que $\bigwedge \Gamma \to \bigvee \Delta$ est
une tautologie. L'intérêt de la relation $\vdash$ à définir est de donner un
système facile de preuve~: pour prouver que $P$ est une tautologie, il suffit
de prouver $\nil\vdash \cons(P,\nil)$ en suivant les règles de base définissant
$\vdash$.

\begin{notation}
  Dorénavant, pour utiliser des listes, nous écrirons $a, \ell$ pour signifie
  $\cons(a,\ell)$ et nous n'écrirons pas $\nil$ lorsque le contexte permet
  clairement de comprendre qu'il s'agit d'une liste. Par exemple, on confondra
  la simple proposition $P$ et la liste $\cons(P,\nil)$. La notation
  $\Gamma,\Delta$ correspond à la concaténation, qui serait notée avec les
  conventions précédentes $\Gamma\oplus\Delta$.
\end{notation}

\begin{definition}[Calcul des séquents]
  On définit la relation $\vdash \subseteq \List(\Prop)^2$ par les règles
  suivantes:
  \begin{center}
    \AxiomC{$P \in \Gamma$}
    \RightLabel{ax}
    \UnaryInfC{$\Gamma\vdash P$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma,P\vdash \Delta$}
    \AxiomC{$\Theta\vdash \Xi,P$}
    \RightLabel{cut}
    \BinaryInfC{$\Gamma,\Theta\vdash\Delta,\Xi$}
    \DisplayProof

    \vspace{0.5cm}
    \AxiomC{$\Gamma,P,Q,\Gamma'\vdash \Delta$}
    \RightLabel{le}
    \UnaryInfC{$\Gamma,Q,P,\Gamma'\vdash \Delta$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma\vdash \Delta,P,Q,\Delta'$}
    \RightLabel{re}
    \UnaryInfC{$\Gamma\vdash \Delta,Q,P,\Delta'$}
    \DisplayProof

    \vspace{0.5cm}
    \AxiomC{$\Gamma,P,P\vdash \Delta$}
    \RightLabel{lc}
    \UnaryInfC{$\Gamma,P\vdash \Delta$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma\vdash \Delta,P,P$}
    \RightLabel{rc}
    \UnaryInfC{$\Gamma\vdash \Delta,P$}
    \DisplayProof

    \vspace{0.5cm}
    \AxiomC{$\Gamma\vdash \Delta$}
    \RightLabel{lw}
    \UnaryInfC{$\Gamma,P\vdash \Delta$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma\vdash \Delta$}
    \RightLabel{rw}
    \UnaryInfC{$\Gamma\vdash \Delta,P$}
    \DisplayProof

    \vspace{0.5cm}
    \AxiomC{$\Gamma,\top\vdash \Delta$}
    \RightLabel{$\top$}
    \UnaryInfC{$\Gamma\vdash \Delta$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma\vdash\Delta,\bot$}
    \RightLabel{$\bot$}
    \UnaryInfC{$\Gamma\vdash \Delta$}
    \DisplayProof

    \vspace{0.5cm}
    \AxiomC{$\Gamma\vdash \Delta,P$}
    \RightLabel{l$\lnot$}
    \UnaryInfC{$\Gamma,\lnot P\vdash \Delta$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma,P\vdash \Delta$}
    \RightLabel{r$\lnot$}
    \UnaryInfC{$\Gamma\vdash \Delta,\lnot P$}
    \DisplayProof

    \vspace{0.5cm}
    \AxiomC{$\Gamma,P\vdash \Delta$}
    \AxiomC{$\Gamma,Q\vdash \Delta$}
    \RightLabel{l$\lor$}
    \BinaryInfC{$\Gamma,P\lor Q\vdash \Delta$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma\vdash \Delta,P,Q$}
    \RightLabel{r$\lor$}
    \UnaryInfC{$\Gamma\vdash \Delta,P\lor Q$}
    \DisplayProof

    \vspace{0.5cm}
    \AxiomC{$\Gamma,P,Q\vdash \Delta$}
    \RightLabel{l$\land$}
    \UnaryInfC{$\Gamma,P\land Q\vdash \Delta$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma\vdash \Delta,P$}
    \AxiomC{$\Gamma\vdash \Delta,Q$}
    \RightLabel{r$\land$}
    \BinaryInfC{$\Gamma\vdash \Delta,P\land Q$}
    \DisplayProof

    \vspace{0.5cm}
    \AxiomC{$\Gamma,Q\vdash \Delta$}
    \AxiomC{$\Gamma\vdash \Delta,P$}
    \RightLabel{l$\to$}
    \BinaryInfC{$\Gamma,P\to Q\vdash \Delta$}
    \DisplayProof
    \qquad
    \AxiomC{$\Gamma,P\vdash Q,\Delta$}
    \RightLabel{r$\to$}
    \UnaryInfC{$\Gamma\vdash \Delta,P\to Q$}
    \DisplayProof
  \end{center}

  On dit qu'une proposition $P$ est prouvable si $\vdash P$ est dérivable.
\end{definition}

L'objectif de la suite de cette section est de prouver que $\vdash$ définit en
fait exactement les tautologies, au sens suivant~: pour toutes propositions
$P$ et $Q$, $P\vDash Q$ si et seulement si $P\vdash Q$ (ainsi, en prenant par
exemple $P = \top$, on peut montrer que $\vDash P$ si et seulement si
$\vdash P$).

\subsection{Correction du calcul des séquents}

La première étape, qui est la plus simple, est de montrer que le calcul des
séquents est correct, c'est-à-dire que si l'on arrive à dériver
$\Gamma\vdash\Delta$, alors $\bigwedge \Gamma\to\bigvee \Delta$ est une
tautologie. La preuve est simplement une induction sur la relation $\vdash$.
Comme c'est la première longue preuve par induction, nous allons la rédiger
complètement, mais il est d'usage pour prouver une induction dont les cas se
ressemblent de ne prouver que quelques cas les plus significatifs.

Pour commencer, introduisons un lemme permettant de plus facilement travailler
sur le résultat à prouver.

\begin{lemma}\label{lem.cor.uti}
  Soient $\Gamma,\Delta\in\List(\Prop)$ et $\rho$ un environnement, on a
  l'équivalence suivante~:
  \[ \Val_\rho(\bigwedge\Gamma\to\bigvee\Delta) = 1 \iff
  \min_{P\in\Gamma}(\Val_\rho(P)) \leq \max_{P\in\Delta}(P)\]
\end{lemma}

\begin{proof}
  Calculons d'abord $\Val_\rho(\bigwedge\Gamma\to\bigvee\Delta)$~:
  \begin{align*}
    \Val_\rho(\bigwedge\Gamma\to\bigvee\Delta) =&
    \max(1 - \Val_\rho(\bigwedge\Gamma), \Val_\rho(\bigvee\Delta))\\
    =& \max(1 - \min_{P\in \Gamma}(\Val_\rho(P)),\max_{P\in\Delta}(\Val_\rho(P)))
  \end{align*}
  Si cette valeur est $1$, alors deux cas se présentent~:
  \begin{itemize}
  \item $\displaystyle\max_{P \in \Delta}(\Val_\rho(P)) = 1$, ce cas signifiant
    forcément que $\max_{P\in \Delta}(P) \geq \min_{P\in \Gamma}(\Val_\rho(P))$
    puisque $\Val$ est à valeurs dans $\{0,1\}$.
  \item $1 - \min_{P \in \Gamma}(\Val_\rho(P)) = 1$, ou, de façon équivalente,
    $\min_{P\in \Gamma}(\Val_\rho(P)) = 0$, ce cas impliquant encore l'inégalité
    puisque $\Val$ est à valeurs dans $\{0,1\}$.
  \end{itemize}
  Réciproquement, si l'inégalité est vérifiée, alors on raisonne par disjonction
  de cas sur la valeur de $\min_{P\in\Gamma}(\Val_\rho(P))$~:
  \begin{itemize}
  \item si sa valeur est $0$, alors on sait déjà que
    $1 - \min_{P \in \Gamma}(\Val_\rho(P)) = 1$, donc
    $\Val_\rho(\bigwedge \Gamma\to \bigvee \Delta) = 1$.
  \item si sa valeur est $1$, alors par notre inégalité on sait que
    $\max_{P\in\Delta}(\Val_\rho(P)) = 1$, donc
    $\Val_\rho(\bigwedge \Gamma\to \bigvee \Delta) = 1$.
  \end{itemize}

  D'où l'équivalence souhaitée.
\end{proof}

\begin{theorem}[Correction du calcul des séquents]
  Soient $\Gamma,\Delta\in\List(\Prop)$. Si $\Gamma\vdash\Delta$, alors
  $\models \bigwedge \Gamma\to \bigvee \Delta$.
\end{theorem}

\begin{proof}
  Soient $\Gamma,\Delta\in\List(\Prop)$ et $\rho$ un environnement, le résultat
  à montrer est que $\Val_\rho(\bigwedge\Gamma\to\bigvee\Delta) = 1$ sachant que
  $\Gamma\vdash \Delta$. Pour cela, on procède par induction sur $\vdash$, en
  utilisant le \cref{lem.cor.uti} pour avoir à prouver l'inégalité de
  valuations. Comme les opérateurs $\bigvee$ et $\bigwedge$ sont commutatifs et
  idempotents, on déduit directement la validité des règles d'échange et de
  contraction. Pour alléger le nombre de cas, on ne montrera que les règles de
  la colonne de gauche dans les règles définissant $\vdash$, le lecteur pouvant
  facilement inférer comment prouver les règles de la colonne de droite à partir
  de celles-ci (sauf pour cut, que nous traitons), et on laissera le cas de
  $\to$ en exercice~:
  \begin{itemize}
  \item Ax~: Supposons que $P\in\Gamma$. L'inégalité à prouver se résume à
    \begin{align*}
      \min_{R \in \Gamma}(\Val_\rho(R)) &\leq \Val_\rho(P) \\
      &= \max_{R \in \{P\}}(\Val_\rho(R))
    \end{align*}
  \item Cut~: On suppose que
    \begin{equation}\label{eq.cor1}
      \min_{R \in (\Gamma, P)} \Val_\rho(R) \leq \max_{R \in \Delta} \Val_\rho(R)
    \end{equation}
    et
    \begin{equation}\label{eq.cor2}
      \min_{R \in \Theta} \Val_\rho(R) \leq \max_{R \in (\Xi, P)} \Val_\rho(R)
    \end{equation}
    Montrons que
    $\min_{R \in (\Gamma, \Theta)} \Val_\rho(R)
    \leq \max_{R \in (\Delta,\Xi)} \Val_\rho(R)$.
    On raisonne par disjonction de cas sur la valeur de $\Val_\rho(P)$~:
    \begin{itemize}
    \item si $\Val_\rho(P) = 0$, alors en injectant cette équation dans
      \ref{eq.cor2}, on obtient
      \[\min_{R \in\Theta} \Val_\rho(R) \leq \max_{R\in \Xi}\Val_\rho(R)\]
      d'où l'inégalité souhaitée (puisque rajouter des termes dans un minimum
      le fera décroître et rajouter des termes dans un maximum le fera croître).
    \item si $\Val_\rho(P) = 1$, alors on injectant cette équation dans
      \ref{eq.cor1}, on obtient
      \[\min_{R\in \Gamma} \Val_\rho(R) \leq \max_{R\in \Delta} \Val_\rho(R)\]
      d'où l'inégalité souhaitée.
    \end{itemize}
  \item lw~: Supposons que
    $\Val_\rho(\bigwedge \Gamma) \leq \Val_\rho(\bigvee \Delta)$ pour tout
    $\rho$, alors comme
    $\Val_\rho(\bigwedge (\Gamma, P)) \leq \Val_\rho(\bigwedge \Gamma)$ on voit
    directement que
    $\Val_\rho(\bigwedge(\Gamma,P)) \leq \Val_\rho(\bigvee\Delta)$.
  \item $\top$~: Comme $\Val_\rho(\top) = 1$ pour tout $\rho$,
    $\Val_\rho(\bigwedge(\Gamma,\top)) = \Val_\rho(\bigwedge \Gamma)$ d'où le
    résultat.
  \item $\mathrm l\lnot$~: Supposons que
    \begin{equation}\label{eq.cor3}
      \min_{R \in \Gamma} \Val_\rho(R) \leq \max_{R \in (\Delta, P)} \Val_\rho(R)
    \end{equation}
    et montrons que
    $\min_{R \in (\Gamma, \lnot P)} \Val_\rho(R) \leq
    \max_{R \in \Delta} \Val_\rho(R)$. On raisonne par disjonction de cas sur
    $\Val_\rho(P)$~:
    \begin{itemize}
    \item si $\Val_\rho(P) = 0$, alors en injectant cette équation dans
      \ref{eq.cor3}, on obtient
      \[\min_{R \in \Gamma} \Val_\rho(R) \leq \max_{R \in \Delta} \Val_\rho(R)\]
      d'où l'inégalité souhaité en rajoutant un élément dans le minimum.
    \item si $\Val_\rho(P) = 1$, alors
      $\min_{R \in (\Gamma, \lnot P)} \Val_\rho(R) = 0$ donc l'inégalité est
      vérifiée.
    \end{itemize}
  \item $\mathrm l\lor$~: Supposons que
    \begin{equation}\label{eq.cor4}
      \min_{R \in (\Gamma, P)} \Val_\rho(R) \leq \max_{R \in \Delta} \Val_\rho(R)
    \end{equation}
    et
    \begin{equation}\label{eq.cor5}
      \min_{R \in (\Gamma, Q)} \Val_\rho(R) \leq \max_{R \in \Delta} \Val_\rho(R)
    \end{equation}
    et montrons que
    $\min_{R \in (\Gamma, P \lor Q)} \Val_\rho(R) \leq \max_{R \in \Delta} \Val_\rho(R)$.
    On raisonne par disjonction de cas sur la valeur de $\Val_\rho(P)$~:
    \begin{itemize}
    \item si $\Val_\rho(P) = 1$, alors en injectant cette égalité dans
      \ref{eq.cor4}, on obtient
      \[\min_{R \in \Gamma} \Val_\rho(R) \leq \max_{R \in \Delta} \Val_\rho(R)\]
      d'où l'inégalité souhaitée en ajoutant un terme dans le minimum.
    \item si $\Val_\rho(P) = 0$, alors on procède par disjonction de cas sur
      la valeur de $\Val_\rho(Q)$~:
      \begin{itemize}
      \item si $\Val_\rho(Q) = 1$, l'argument précédent fonctionne aussi en
        remplaçant \ref{eq.cor4} par \ref{eq.cor5}.
      \item si $\Val_\rho(Q) = 0$, alors on sait que $\Val_\rho(P\lor Q) = 0$
        avec nos deux équations, donc
        $\min_{R \in (\Gamma, P \lor Q)} \Val_\rho(R) = 0$, d'où l'inégalité.
      \end{itemize}
    \end{itemize}
  \item $\mathrm l\land$~: On voit que
    $\Val_\rho(\bigwedge(\Gamma,P,Q)) = \Val_\rho(\bigwedge(\Gamma, P \land Q))$
    par associativité de $\bigwedge$, donc si l'on suppose que
    $\Val_\rho(\bigwedge(\Gamma,P,Q)) \leq \Val_\rho(\bigvee\Delta)$, on en
    déduit directement que
    $\Val_\rho(\bigwedge(\Gamma,P\land Q)) \leq\Val_\rho(\bigvee\Delta)$.
  \end{itemize}
  Donc, par induction, si $\Gamma\vdash \Delta$ alors
  $\models \bigwedge\Gamma\to\bigvee\Delta$.
\end{proof}

\begin{exercise}
  Montrer les cas manquants dans la preuve précédente.
\end{exercise}

On en déduit donc, comme $\bigwedge P = P$ et $\bigvee Q = Q$, que
$P\vdash Q \implies P \vDash Q$.

\begin{remark}
  En utilisant le théorème de correction, on en déduit que pour
  $\mathcal P\subseteq \Prop$ et $P\in \Prop$, si l'on trouve
  $\Gamma\in\List(\mathcal P)$ tel que $\Gamma\vdash P$, alors
  $\mathcal P \vDash P$.

  On peut donc définir la relation
  $\vdash \subseteq \powerset(\Prop)\times \Prop$ par
  \[\mathcal P\vdash P \defeq \exists \Gamma\in\List(\mathcal P),
  \Gamma\vdash P\]
  et les résultats précédents prouvent que $\vdash\subseteq\vDash$. Nous allons
  maintenant montrer le sens réciproque~: $\vDash\subseteq\vdash$. Ce résultat
  s'appelle la complétude.
\end{remark}

\begin{theorem}[Complétude du calcul des séquents \cite{belghiti2016clefs}]
  Pour tous $\mathcal P\subseteq \Prop$ et $P\in \Prop$, si $\mathcal P\vDash P$
  alors il existe $\Gamma\in\List(\mathcal P)$ tel que $\Gamma\vdash P$.
\end{theorem}

\begin{proof}
  Tout d'abord, par théorème de compacité, il nous suffit de traiter le cas
  fini~: pour $\Gamma\in\List(\Prop)$, en prenant $F_\Gamma$ l'ensemble de
  formules associé, si $F_\Gamma\vDash P$ alors $F\vdash P$.

  On définit la relation $\vdash^*$ de façon analogue à $\vdash$ mais en
  ajoutant la règle suivante~:
  \begin{prooftree}
    \AxiomC{}
    \RightLabel{ax$^\dagger$}
    \UnaryInfC{$x_1,\ldots,x_n,\top,\ldots,\top\vdash^*
      y_1,\ldots,y_p,\bot,\ldots,\bot$}
  \end{prooftree}
  où $x_1,\ldots,x_n,y_1,\ldots,y_n$ sont des variables propositionnelles
  toutes deux à deux distinctes, on ajoute un nombre arbitraire de $\top$ à
  gauche et de $\bot$ à droite, et en remplaçant la règle axiome, les règles
  d'affaiblissement et la règle cut par la règle axiomes renforcée~:
  \begin{prooftree}
    \AxiomC{}
    \RightLabel{ax'}
    \UnaryInfC{$\Gamma,P\vdash^* \Delta,P$}
  \end{prooftree}

  On prouve maintenant que pour tous $\Gamma,\Delta\in\List(\Prop)$,
  $\Gamma\vdash^*\Delta$. On raisonne par induction sur le nombre de
  constructeurs apparaissant au total dans le séquent $\Gamma\vdash^* \Delta$,
  c'est-à-dire la somme du nombre de constructeurs de chaque formule~:
  \begin{itemize}
  \item s'il n'y a aucun constructeur dans $\Gamma,\Delta$, alors plusieurs
    séquents sont possibles. En utilisant potentiellement la règle de
    contraction pour éliminer les variables en double du même côté, il nous
    reste à traiter ces différents cas~:
    \begin{itemize}
    \item si le séquent contient un $\top$ à droite ou un $\bot$ à gauche,
      alors on peut prouver $\Gamma\vdash^* \Delta,\top$
      (respectivement $\Gamma,\bot\vdash^*\Delta$)~:
      \begin{center}
        \AxiomC{}
        \RightLabel{ax'}
        \UnaryInfC{$\Gamma,\top\vdash^* \Delta,\top$}
        \RightLabel{$\top$}
        \UnaryInfC{$\Gamma\vdash^* \Delta,\top$}
        \DisplayProof
        \qquad
        \AxiomC{}
        \RightLabel{ax'}
        \UnaryInfC{$\Gamma,\bot\vdash^* \Delta\bot$}
        \RightLabel{$\bot$}
        \UnaryInfC{$\Gamma,\bot\vdash^*\Delta$}
      \end{center}
    \item si le séquent est de la forme
      $x_1,\ldots,x_n,\top,\ldots,\top\vdash y_1,\ldots,y_p,\bot,\ldots,\bot$
      où toutes les variables sont deux à deux distinctes, alors la règle
      $\mathrm{Ax}^\dagger$ donne le résultat.
    \item si le séquent est de la forme $\Gamma,x\vdash^* \Delta,x$, alors la
      règle ax' donne le résultat directement.
    \end{itemize}
    On peut donc toujours prouver un séquent ne contenant aucun constructeur.
  \item Si $\Gamma = \Gamma', \lnot P$, alors par $\mathrm{l}\lnot$ il nous
    suffit de prouver $\Gamma'\vdash^* \Delta, P$, ce qui est vérifié par
    notre hypothèse d'induction.
  \item si $\Gamma = \Gamma', P\to Q$, alors par $\mathrm{l}\to$ il nous
    suffit de prouver à la fois $\Gamma', Q \vdash^* \Delta$ et
    $\Gamma'\vdash^* P$, qui ont tous les deux strictement moins de
    constructeurs que notre séquent original~: on peut donc appliquer notre
    hypothèse d'induction.
  \item si $\Gamma = \Gamma', P\lor Q$, alors il nous suffit de montrer
    à la fois $\Gamma', P\vdash^* \Delta$ et $\Gamma',Q\vdash^*\Delta$ qui
    contiennent strictement moins de constructeurs que le séquent original.
  \item si $\Gamma = \Gamma', P\land Q$, alors il nous suffit de
    montrer $\Gamma', P,Q \vdash^* \Delta$ qui est vérifié par hypothèse
    d'induction.
  \item les cas où on veut éliminer un constructeur qui est dans $\Delta$
    sont parfaitement analogues aux précédents.
  \end{itemize}
  D'où le fait que tout séquent $\Gamma\vdash^* \Delta$ est dérivable.

  Maintenant, prouvons que si $\Gamma\vdash^*\Delta$ et $\Gamma\nvdash\Delta$,
  alors $\Gamma\nvDash\Delta$ (où $\Gamma\vDash \Delta$ signifie que pour toute
  valuation
  $\rho$, $\Val_\rho(\bigwedge \Gamma) \leq \Val_\rho(\bigvee \Delta)$).
  On procède par induction sur $\vdash^*$~:
  \begin{itemize}
  \item si la dernière règle utilisée est ax', alors, puisque le séquent se
    démontre avec la règle axiome et les règles d'affaiblissement, le fait que
    $\Gamma\nvdash \Delta$ est absurde.
  \item si la dernière règle utilisée est $\mathrm{ax}^\dagger$, alors on
    construit la valuation invalidant le séquent en mettant tous les $x_i$ à
    $1$ et tous les $y_i$ à $0$.
  \item si la dernière règle utilisée est un échange, une contraction, $\top$
    ou $\bot$, alors une valuation invalidant le séquent de départ invalide
    aussi le séquent d'arrivée. Cela vaut aussi pour $\mathrm{r}\lor$,
    $\mathrm{l}\land$ et $\mathrm{r}\to$.
  \item si la dernière règle utilisée est $\mathrm{l}\lor$ (un raisonnement
    analogue fonctionne pour $\mathrm{r}\land$ et $\mathrm{l}\to$), alors
    en considérant que la conclusion de la règle est
    $\Gamma, P \lor Q \vdash^* \Delta$, on suppose que
    $\Gamma, P \vdash^* \Delta$ et $\Gamma, Q \vdash^* \Delta$.
    Or, comme $\Gamma, P\lor Q\nvdash \Delta$, on ne peut avoir à la fois
    $\Gamma, P \vdash \Delta$ et $\Gamma, Q \vdash \Delta$. Sans perte de
    généralité puisque $P$ et $Q$ jouent des rôles symétriques, on suppose que
    $\Gamma, P \nvdash \Delta$. Alors, par hypothèse d'induction, on sait que
    $\Gamma, P \nvDash \Delta$, donc on trouve $\rho$ telle que
    \[\min_{R \in (\Gamma, P)} \Val_\rho(R) > \max_{S \in \Delta} \Val_\rho(S)\]
    On en déduit qu'il existe une proposition $R \in (\Gamma, P)$ telle que
    $\Val_\rho(R) = 1$ et que pour tout $S\in \Delta, \Val_\rho(S) = 0$.
    Si $R \in \Gamma$, alors on en déduit directement que
    \[\min_{R\in (\Gamma, P \lor Q)} \Val_\rho(R) > \max_{S\in\Delta} \Val_\rho(S)\]
    et donc que $\Gamma, P \lor Q \nvDash \Delta$. Sinon, cela signifie que
    $R = P$, donc que $\Val_\rho(P) = 1$, d'où $\Val_\rho(P\lor Q) = 1$, donc
    \[\min_{R\in (\Gamma, P \lor Q)} \Val_\rho(R) > \max_{S\in\Delta} \Val_\rho(S)\]
    Ainsi, dans tous les cas, $\Gamma, P \lor Q \nvDash \Delta$.
  \end{itemize}

  Ainsi, comme $\Gamma\vdash^*\Delta$ est toujours vérifié, on en déduit que
  $\Gamma\nvdash\Delta\implies\Gamma\nvDash\Delta$, d'où par contraposée
  $\Gamma\vDash\Delta\implies\Gamma\vdash\Delta$.
\end{proof}

\begin{remark}
  Même si cette démonstration est grandement inspirée de celle proposée dans
  \cite{belghiti2016clefs} et adaptée pour prendre en compte les autres
  constructeurs propositionnels, relevons que cette démonstration ne peut
  fonctionner qu'avec un ensemble de règles très précis~: il faut que les règles
  conservent la fausseté en plus d'être correctes pour qu'une preuve fausse dès
  le début le reste. C'est en particulier la raison pour laquelle la définition
  de $\vdash^*$ n'utilise pas la règle de coupure.
\end{remark}

Ainsi, nous avons un système syntaxique $\vdash$ permettant d'entièrement
caractériser la relation $\vDash$, qui est une relation sémantique (elle relie
les propositions par leur sens, là où $\vdash$ n'est qu'un système formel,
encodable par exemple sur un ordinateur).
