\chapter{Induction}
\label{chp.induction}

\minitoc

L'un des outils fondamentaux en logique est l'induction. Intuitivement, elle
peut se voir comme une généralisation du principe de récurrence. Nous allons
cependant adopter un formalisme différent de celui utilisé pour faire une simple
récurrence. Les objets principaux sur lesquels nous utiliserons l'induction sont
les ensembles inductifs et les relations inductives, que nous présenterons. Ces
deux objets sont associés à des formalismes différents : le premier aux
grammaire en forme de Backus-Naur, et le deuxième aux points fixes et à la
théorie des treillis. Comme la théorie des treillis sera étudiée plus tard dans
cette partie préliminaire, nous ne traiterons qu'un cas restreint suffisant pour
le travail sur l'induction.

L'objectif de ce chapitre est de donner une justification mathématique aux
procédés qui seront utilisés par la suite, et d'offrir un modèle mathématique
derrière le formalisme introduit, pour le lecteur qui en aurait besoin. Le point
essentiel est avant tout de comprendre comment fonctionne une preuve par
induction et comment utiliser les objets inductifs, puisqu'ils seront utilisés
sans arrêt par la suite. Cependant, les justifications mathématiques données
sont partielles : tous les cas ne se ramènent pas à ceux traités de façon
évidente. Le lecteur le plus prudent devra trouver comment adapter le formalisme
donné dans ce chapitre aux multiples variantes qui seront utilisées sans le dire
par la suite.

\section{Ensemble inductif}

\subsection{Construction d'un ensemble inductif}

Au niveau intuitif, les ensembles finis semblent avoir une réalité plus
robuste que les ensembles infinis. Il est en effet très facile de se convaincre
à partir de règles simples qu'il existe un ensemble à $3$ éléments, ou à $n$
éléments pour $n$ aussi grand que l'on veut (bien que se convaincre qu'il existe
un ensemble à $300!$ éléments semble légèrement plus long). Cette robustesse
découle du fait qu'on peut explicitement les construire, et cette possibilité
n'existe que pour un ensemble fini. Pourtant, l'ensemble $\mathbb N$ tend aussi
à être plus facilement accepté qu'un ensmeble tel que $\mathbb R / \mathbb Q$.
Un point essentiel qui rend le premier ensemble logiquement plus simple que le
deuxième est qu'il est facile à engendrer : l'ensemble $\mathbb N$ est constitué
de l'élément $0$ et de l'opération $S$ définie par $n \mapsto n + 1$, et tout
autre élément de $\mathbb N$ peut être construit à partir de ces deux éléments.
Sa structure est donc fondamentalement simple, et peut être décrite en des
termes finis.

C'est exactement cette idée de structure générée par des termes finis qui est
formalisée par les ensembles inductifs. Un ensemble inductif va être un ensemble
obtenu par une liste de générateurs, chaque générateur ayant une arité (un
nombre d'objets qu'il prend en entrée). Dans cette définition d'ensemble
inductif, l'exemple canonique est bien sûr $\mathbb N$ lui-même, qu'on peut
définir par :
\begin{itemize}
\item un constructeur sans argument, $0$
\item un constructeur à un argument, $S$
\end{itemize}

Avant de donner la définition d'ensemble inductif, nous allons donner un
formalisme pour parler des constructeurs.

\begin{definition}[Signature]
  Une signature est un couple $C,\alpha$ tel que $\alpha : C \to \mathbb N$.
  On appelle $C$ l'ensemble des constructeurs et, pour $c \in C$, $\alpha(c)$
  est appelé l'arité de $c$.
\end{definition}

Une signature sera généralement donnée sous forme dite de Backus-Naur. Cette
présentation se décompose de la façon suivante :
$$a,b,\ldots ::= \mathrm{cas}\;1 \mid \mathrm{cas}\;2 \mid \ldots$$
où $a,b,\ldots$ représentent les éléments que les constructeurs définissent,
et où chaque cas est la définition d'un nouveau constructeur (ou d'une famille
de constructeurs). Par exemple pour le cas de $\mathbb N$, nous avons :
$$n ::= 0 \mid S\;n$$
Il est fréquent d'employer des variables qui seront quantifiées hors de la
définition à proprement parler, comme
$$l ::= \mathrm{nil} \mid \mathrm{cons}(a,l)$$
où $a \in A$ et $A$ est certain ensemble fixé au préalable. Cette définition
doit se lire comme l'ensemble $(\{\mathrm{nil}\} \cup A,\alpha)$ où $\alpha$
est défini par :
$$
\begin{array}{rcccl}
  \alpha &:& C & \longrightarrow & \mathbb N\\
  & & \mathrm{nil} & \longmapsto & 0 \\
  & & a (\in A) & \longmapsto & 1
\end{array}
$$

Voyons maintenant comment associer à une signature un ensemble généré par les
constructeurs donnés dans la signature. L'ensemble généré doit être un ensemble
$X$ contenant, pour chaque $x_1,\ldots,x_n \in X$ et $c \in C$ d'arité $n$,
l'objet $c(x_1,\ldots,x_n)$, et ne doit contenir que les objets de cette forme.
Nous procédons alors par le bas : un premier ensemble est construit par
l'ensemble $C_0 = \{ c \in C \mid \alpha(c) = 0\}$, puis l'ensemble $C_1$ est
construit par $C_1 = C_0 \cup \{ c(x_1,\ldots,x_n) \mid c \in C, x_1,\ldots,
x_n \in C_0, \alpha(c) = n\}$ et ainsi de suite. Comme $c$ est simplement un
élément dans notre cas, écrire $c(x_1,\ldots,x_n)$ n'a pas de sens, c'est
pourquoi l'on va utiliser à la place $(c,x_1,\ldots,x_n)$.

\begin{definition}[Ensemble inductif sur une signature]
  Soit $(C,\alpha)$ une signature, on définit la suite d'ensembles
  $(X_i)_{i\in\mathbb N}$ par :
  \begin{itemize}
  \item $X_0 = \varnothing$
  \item $X_{n+1} = \{ (c,x_1,\ldots,x_p) \mid c\in C, (x_1,\ldots,x_p)\in (X_n)^p,
    \alpha(c) = p \}$
  \end{itemize}

  L'ensemble inductif engendré par $(C,\alpha)$ est alors l'ensemble
  $$X = \bigcup_{n\in \mathbb N} X_n$$
\end{definition}

La définition donnée n'est pas exactement celle décrite plus haut, mais la
proposition suivante assure que l'union finale génère bien le même ensemble
avec les deux méthodes.

\begin{proposition}
  Soit $(C,\alpha)$ une signature, $X$ l'ensemble inductif engendré par cette
  signature et $(X_n)$ la suite précédemment construite. Alors
  $$\forall n,m \in \mathbb N, n \leq m \implies X_n \subseteq X_m$$
\end{proposition}

\begin{proof}
  On procède par récurrence sur $n$ :
  \begin{itemize}
  \item comme $X_0 = \varnothing$, il est évident que
    $\varnothing \subseteq X_m$ pour tout $m \in\mathbb N$.
  \item supposons que $X_n \subseteq X_m$ pour tout $m \geq n$. Alors
    $$X_{n+1} = \{(c,x_1,\ldots,x_p)\mid c\in C, (x_1,\ldots,x_p)\in(X_n)^p,
    \alpha(c) = p\}$$
    mais par inclusion, comme $(x_1,\ldots,x_p)\in (X_n)^p$, on en déduit que
    $(x_1,\ldots,x_p)$ est aussi dans $(X_m)^p$, pour tout $m \geq n$. Ainsi
    $(c,x_1,\ldots,x_p) \in X_{m+1}$ pour tout $m \geq n$, donc
    $X_{n+1}\subseteq X_m$ pour tout $m \geq n+1$.
  \end{itemize}
\end{proof}

\subsection{Récursion et induction}

Maintenant qu'une construction a été donnée d'un ensemble inductif, il faut
vérifier que le comportement que l'on a décrit est en accord avec le
comportement réel de l'ensemble que l'on a construit. Nous avons dit que
l'ensemble engendré par $(C,\alpha)$ doit contenir exactement les éléments de
la forme $c(x_1,\ldots,x_n)$ où $x_i \in X$ pour tout $i\in\{1,\ldots,n\}$, mais
une autre façon de penser le fait que l'ensemble ne contient que des
applications de constructeurs est le fait qu'une fonction partant d'un ensemble
inductif est exactement spécifiée par son comportement sur les constructeurs.
De telle fonctions sont appelées récursives, car elles peuvent faire appel à
elles-mêmes pour s'appliquer sur les arguments d'un constructeurs, comme nous le
verrons en pratique. Nous verrons ensuite que ce principe de définition
récursive peut se modifier pour donner le principe d'induction, un analogue à
la preuve par récurrence pour un ensemble inductif quelconque.

\begin{theorem}[Propriété universelle des ensembles inductifs]
  Soit $(C,\alpha)$ une signature, et $X$ l'ensemble associé à cette signature.
  Soit un ensemble $Y$ quelconque.
  Soit une famille de fonctions $\{f_c\}_{c\in C}$ telles que pour tout $c\in C$,
  $f_c : Y^{\alpha(c)} \to Y$ (avec la convention que $Y^0 = \{*\}$ est un
  singleton quelconque). Alors il existe une unique fonction $f : X \to Y$
  telle que
  $$\forall c\in C, \forall (x_1,\ldots,x_p)\in X^{\alpha(c)},
  f((c,x_1,\ldots,x_p)) = f_c (f(x_1),\ldots,f(x_p))$$
\end{theorem}

On peut représenter l'équation précédente par le diagramme suivant, où l'égalité
signifie que le diagramme commute, c'est-à-dire que les deux chemins possibles
pour aller d'un coin à l'autre du carré sont égaux.

\begin{center}
  \begin{tikzcd}
    X^{\alpha(c)} \ar[r,"f^{\alpha(c)}"]\ar[d,"c"] & Y^{\alpha(c)} \ar[d,"f_c"] \\
    X \ar[r,"f"] & Y
  \end{tikzcd}
\end{center}

\begin{proof}
  Soit $(X_n)$ la suite d'ensemble construite précédemment pour définir $X$. On
  va prouver par récurrence sur $n$ la proposition suivante :
  $$\forall n\in \mathbb N, \exists ! f : X_n \to Y, \forall c \in C,
  \forall (x_1,\ldots,x_p)\in (X_n)^{\alpha(c)}, f((c,x_1,\ldots,x_p))
  = f_c(f_n(x_1),\ldots,f_n(x_p))$$
  \begin{itemize}
  \item Si $n = 0$, il existe une unique fonction $f_0 : \varnothing \to Y$ et
    elle vérifie la propriété par vacuité.
  \item Soit $n \in \mathbb N$. Supposons qu'il existe une unique fonction
    $f_n : X_n \to Y$ telle que
    $$\forall c\in C, \forall (x_1,\ldots,x_p)\in (X_n)^{\alpha(c)},
    f((c,x_1,\ldots,x_p)) = f_c(f(x_1),\ldots,f(x_p))$$
    On définit alors
    $$\begin{array}{rcccl}
      f_{n+1} &:& X_{n+1} &\longrightarrow & Y \\
      & & (c,x_1,\ldots,x_p) & \longmapsto & f_c(f_n(x_1),\ldots,f_n(x_p))
    \end{array}$$
    On remarque que cette fonction vérifie bien la propriété. De plus, si une
    autre fonction $g$ vérifie la propriété, alors pour $x\in X_{n+1}$, on trouve
    $c\in C$ et $x_1,\ldots,x_p \in X_n$ tels que $x = (c,x_1,\ldots,x_p)$, on a
    alors
    \begin{align*}
      f_{n+1}(x) &= f((c,x_1,\ldots,x_p)) \\
      &= f_c(f_n(x_1),\ldots,f_n(x_n)) \\
      &= g((c,x_1,\ldots,x_p))\\
      &= g (x)
    \end{align*}
    Donc pour tout $x\in X_{n+1}$, $f_{n+1} = g(x)$, ce qui signifie que
    $f_{n+1} = g$, d'où l'unicité de $f_{n+1}$.
  \end{itemize}

  Soit $x \in X$, par définition on trouve $n\in \mathbb N$ tel que $x \in X_n$,
  et on peut donc définir $f(x) = f_n(x)$. Pour montrer que la fonction est
  unique, il suffit de remarquer que toute fonction $X \to Y$ vérifiant les
  prémisses du théorème induit une fonction sur chaque $X_n$, et doit donc
  coïncider avec chaque $f_n$ sur $X_n$.
\end{proof}

\begin{remark}
  Pour une signature $(C,\alpha)$ et un ensemble associé $X$, chaque $c\in C$
  peut maintenant s'interpréter comme une fonction $c : X^{\alpha(c)}\to X$. Nous
  confondrons dorénavant le constructeur et la fonction associée, et écrirons
  donc sans distinction $(c,x_1,\ldots,x_p)$ et $c(x_1,\ldots,x_p)$ pour un
  constructeur $c \in C$.
\end{remark}

Cet outil nous permet maintenant de définir des fonctions dont le domaine est
un ensemble inductif en utilisant sa structure.

\begin{example}
  Donnons un premier exemple de fonction récursive : la fonction
  $d :n\mapsto 2n$, définie de $\mathbb N$ dans $\mathbb N$. En effet, on peut
  la décrire par
  \begin{itemize}
  \item $d(0) = 0$
  \item $d(S\;n) = S\;S\;d(n)$
  \end{itemize}
  nous donnant alors une définition de $d$ grâce au théorème précédent.
\end{example}

\begin{example}
  Un exemple à la fois d'ensemble inductif et de fonction récursive est le
  suivant. Soit $A$ un ensemble quelconque, on définit la signature des listes
  sur $A$ par la grammaire suivante :
  $$\ell ::= \mathrm{nil}\mid \mathrm{cons}(a,\ell)$$
  où $a\in A$. L'ensemble $\mathrm{List}(A)$ est alors l'ensemble inductif
  associé. On définit alors la fonction $|-|$ donnant la longueur d'une
  liste :
  \begin{itemize}
  \item $|\mathrm{nil}| = 0$
  \item $|\mathrm{cons}(a,\ell)| = 1 + |\ell|$
  \end{itemize}
\end{example}

\begin{exercise}
  Soit $A$ un ensemble. Donner une signature définissant l'ensemble
  $\mathrm{BinTree}(A)$ des arbres
  binaires étiquetés par $A$, constitué d'un objet arbre vide et d'un
  constructeur binaire $\mathrm{node}$ prenant en argument un élément $a$ de $A$
  et deux arbres $g$ et $d$ et retournant un nouvel arbre binaire, d'étiquette
  $a$ et dont les deux sous-arbres sont $g$ et $d$.

  Définir une fonction $h : \mathrm{BinTree}(A) \to \mathbb N$ donnant la
  hauteur d'un arbre, c'est-à-dire la longueur du plus long chemin entre la
  racine de l'arbre (la première étiquette) et une feuile (un arbre vide qui est
  sous-arbre). On prend comme convention que $h(\mathrm{nil}) = 0$.

  Définir une fonction $|-| : \mathrm{BinTree}(A) \to \mathbb N$ donnant le
  nombre d'étiquettes d'un arbre.
\end{exercise}

\begin{exercise}
  En utilisant la structure inductive de $\mathbb N$, définir la fonction
  $+ : \mathbb N \times \mathbb N \to \mathbb N$. On pourra pour cela définir
  la fonction $n \mapsto (m \mapsto n + m)$ et faire une fonction récursive sur
  l'argument $n$.
\end{exercise}

Un procédé similaire est celui d'induction. Là où la récursion nous permet de
définir une fonction depuis un ensemble inductif, l'induction va nous permettre
de faire une preuve sur un ensemble inductif. Il s'agit donc, au lieu de donner
une fonction $X \to Y$, de donner un prédicat $P \subseteq X$ et de montrer que
$P = X$.

\begin{theorem}[Principe d'induction]
  Soit $(C,\alpha)$ une signature et $X$ l'ensemble inductif associé. Soit
  $P\subseteq X$ un prédicat sur $X$. Si pour tous $c\in C$ et
  $x_1,\ldots,x_p\in X^{\alpha(c)}$, la propriété
  $$x_1\in P \text{ et } x_2\in P \text{ et }\ldots \text{ et }x_p\in P \implies
  c(x_1,\ldots,x_p)\in P$$ est vérifiée,
  alors $P = X$.
\end{theorem}

\begin{proof}
  Pour prouver ce résultat, il suffit de montrer que pour tout $n\in\mathbb N$,
  $X_n \subseteq P$ pour $(X_n)$ la suite d'ensembles construisant $X$. En
  effectuant une récurrences sur $n$ :
  \begin{itemize}
  \item Si $n = 0$, alors $\varnothing \subseteq P$.
  \item Supposons que $X_n \subseteq P$ pour $n \in \mathbb N$. Soit
    $x \in X_{n+1}$. Par définition de $X_{n+1}$, on trouve $c \in C$ et
    $x_1,\ldots,x_p \in X_n$ tels que $x = c(x_1,\ldots,x_p)$. Par hypothèse
    de récurrence, on en déduit que pour tout $i\in\{1,\ldots,p\}$, $x_i\in P$.
    Il vient donc, avec l'hypothèse du théorème sur $P$, que
    $c(x_1,\ldots,x_p)\in P$.

    On en conclus que $P\subseteq X_{n+1}$.
  \end{itemize}

  Ainsi, par récurrence, pour tout $n\in \mathbb N$, $X_n \subseteq P$.
  Cela montre alors que
  $$\bigcup_{n \in \mathbb N} X_n \subseteq P$$
  ce qu'il fallait démontrer.
\end{proof}

On peut affiner ce résultat en distinguant deux sortes de constructeurs : d'un
côté les constructeurs d'arité $0$, qui sont des constantes, et de l'autre les
constructeurs d'arité supérieure à $1$. Le théorème précédent nous dit que pour
prouver une proposition $P$ sur un ensemble inductif, il suffit de prouver qu'il
contient les constantes et qu'il est stable par chaque constructeur. On remarque
que dans le cas de $\mathbb N$, engendré par $0$ et $S$, ce principe nous dit
qu'une partie $P$ contenant $0$ et telle que
$\forall n\in\mathbb N, n\in P \implies n+1\in P$ est exactement $\mathbb N$ :
c'est le principe de récurrence.

Ainsi, puisque nous prouvons le principe d'induction à partir du principe de
récurrence, et puisque le principe de récurrence est un cas particulier du
principe d'induction, les deux sont logiquement équivalents. L'induction,
cependant, est conceptuellement plus intéressante puisqu'elle peut s'utiliser
dans plus de cas.

\begin{exercise}
  On considère $\mathbb N$ comme un ensemble inductif, et la fonction $d$
  définie dans un exemple précédent. Montrer que pour tout $n \in \mathbb N$,
  $d(n)$ est pair. On prendra comme définition de pair le prédicat
  $\mathrm{pair}(n) \defeq \exists m\in\mathbb N, n = 2 \times m$.
\end{exercise}

\begin{exercise}
  Soit un ensemble $A$. On définit
  $\oplus : \mathrm{List}(A) \times \mathrm{List}(A)\to \mathrm{List}(A)$ par
  induction sur le premier argument:
  \begin{itemize}
  \item Pour tout $\ell\in \mathrm{List}(A)$, $\mathrm{nil} \oplus \ell = \ell$.
  \item Pour tous $\ell,\ell'\in\mathrm{List}(A), a\in A$,
    $\mathrm{cons}(a,\ell) \oplus \ell' = \mathrm{cons}(a,\ell \oplus \ell')$.
  \end{itemize}

  Montrer que
  $$\forall \ell,\ell'\in \mathrm{List}(A), |\ell\oplus \ell'|=|\ell|+|\ell'|$$
\end{exercise}

\section{Relation inductive}

\subsection{Construction d'une relation inductive}

Une façon de considérer les ensembles inductif est, étant donnée une signature,
de prendre le plus petit ensemble stable par les constructeurs de cette
signature. Le problème, pour faire cela, est que nous n'avons d'ensemble sur
lequelle travailler a priori. C'est pourquoi la construction précédente
définissait chaque ensemble intermédiaire pour en prendre l'union. Au contraire,
pour définir les relations inductives, nous avons un ensemble ambiant et nous
pouvons donc travailler sur la notion de plus petit ensemble stable. Pour
pouvoir mieux appréhender les relations inductives, nous allons directement
introduire les règles d'inférence.

Rappelons la définition d'une relation.

\begin{definition}[Relation]
  Soit $X$ un ensemble. On appelle relation sur $X$ une partie $R\subseteq X^n$
  où $n\in\mathbb N$ est appelé l'arité de la relation $R$.
\end{definition}

Une règle d'inférence, elle, va relier des relations.

\begin{definition}[Règle d'inférence]
  On appelle règle d'inférence une présentation de la forme suivante:
  \begin{prooftree}
    \AxiomC{$P_1$}
    \AxiomC{$P_2$}
    \AxiomC{$\cdots$}
    \AxiomC{$P_n$}
    \RightLabel{r}
    \QuaternaryInfC{$P$}
  \end{prooftree}
  Où $P_1,\ldots,P_n$ sont appelées les prémisses de la règle, et $P$ est
  appelée la conclusion de la règle. On dit que la règle est juste si, lorsque
  toutes les prémisses de la règle sont vérifiées, alors la conclusion est aussi
  vérifiée.

  Une règle peut contenir plusieurs paramètres, par exemple
  \begin{prooftree}
    \AxiomC{$a = b$}
    \AxiomC{$P(a)$}
    \BinaryInfC{$P(b)$}
  \end{prooftree}
  auquel cas la règle est juste lorsqu'elle est juste pour chaque instance
  possible de ces paramètres. Dans l'exemple, on suppose que $a$ et $b$ sont
  quantifiés sur un certain ensemble $A$, et la règle est donc juste lorsque
  $\forall a,b\in A, ((a = b) \text{ et } P(a)) \implies P(b)$.

  \'Etant donnée une règle r comme précédemment avec un paramètre $X$ non
  spécifié, on notera $R\models \mathrm{r}$ si la règle r est juste en prenant
  $R$ pour le paramètre $X$. De même, on notera
  $R,x_1,\ldots,x_n\models \mathrm{r}$ dans le cas où l'ont remplace plusieurs
  paramètres.
\end{definition}

Ainsi, à une règle de la forme
\begin{prooftree}
  \AxiomC{$P_1$}
  \AxiomC{$P_2$}
  \AxiomC{$\cdots$}
  \AxiomC{$P_n$}
  \RightLabel{r}
  \QuaternaryInfC{$P$}
\end{prooftree}
avec un paramètre $R$ fixé d'arité $n\in\mathbb N$ et sur un ensemble $E$, on
peut associer une fonction
$$\begin{array}{rcccl}
  r &:& \mathcal P(E^n) & \longrightarrow & \mathcal P(E^n) \\
  & & R & \longmapsto & R \cup
  \{ (x_1,\ldots,x_n) \in E^n\mid R,x_1,\ldots,x_n\models \mathrm {r}\}
\end{array}$$
où tous les paramètres n'apparaissant pas dans la conclusion sont quantifiés de
façon existentielle.

\begin{example}
  Prenons la règle
  \begin{prooftree}
    \AxiomC{$x = y$}
    \RightLabel{refl}
    \UnaryInfC{$R(x,y)$}
  \end{prooftree}
  exprimant que la règle $R$ est réflexive. La fonction $\mathrm{refl}$ est
  alors $R \mapsto R \cup \{(x,x)\mid x \in E\}$.

  Dans ce genre de cas, on écrira de façon plus compacte la règle par
  \begin{prooftree}
    \AxiomC{}
    \UnaryInfC{$R(x,x)$}
  \end{prooftree}
\end{example}

\begin{example}
  La règle précédente n'utilisait pas $R$ dans ses prémisses, un exemple
  l'utilisant est la règle exprimant la transivité :
  \begin{prooftree}
    \AxiomC{$R(x,y)$}
    \AxiomC{$R(y,z)$}
    \RightLabel{trans}
    \BinaryInfC{$R(x,z)$}
  \end{prooftree}
  Dans ce cas, l'image de $R$ par $\mathrm{trans}$ est l'ensemble
  $R \cup \{ (x,z) \in E^2\mid \exists z \in E, R(x,y)\text{ et } R(y,z)\}$.
\end{example}

Supposons maintenant que nous ayons une relation $R$ et une règle $\mathrm r$,
$R$ ne vérifiant pas forcément $\mathrm r$. Nous cherchons alors à construire à
partir de $R$ une relation vérifiant $\mathrm r$. Une remarque essentielle : si
$R$ vérifie $\mathrm r$, alors $R$ est un point fixe de la fonction $r$
associée. On va ainsi chercher à créer un point fixe de la fonction associée.
Pour cela, nous allons donner un théorème essentiel en logique : le théorème de
Knaster-Tarski.

\begin{theorem}[Knaster-Tarski (faible)]
  Soit un ensemble $E$ quelconque, et une fonction
  $f : \mathcal P(E) \to \mathcal P(E)$ croissante pour $\subseteq$,
  c'est-à-dire telle que
  $$\forall A,B\in\mathcal P(E), A\subseteq B \implies f(A)\subseteq f(B)$$
  Alors il existe un plus petit point fixe de $f$ pour $\subseteq$, ou de façon
  équivalente il existe un élément $A\in \mathcal P(E)$ tel que $f(A)=A$ et tel
  que pour tous $B\in\mathcal P(E)$ tel que $f(B)=B$, $A\subseteq B$.
\end{theorem}
\begin{proof}
  Pour commencer, définissons l'ensemble des pré-points fixes de $f$, qui est
  $$\mathrm{prefix}(f) = \{ A \in \mathcal P(E)\mid f(A)\subseteq A\}$$
  Soit $\alpha = \bigcap \mathrm{prefix}(f)$, montrons que $\alpha$ est dans
  $\mathrm{prefix}(f)$ :

  Pour cela, il suffit de montrer que $f(\alpha)\subseteq \alpha$, mais comme
  $\alpha$ est une intersection, il suffit de montrer que pour tout
  $A\in\mathrm{prefix}(f), f(\alpha)\subseteq A$. Pour montrer cela, on
  remarque par transitivité de $\subseteq$ qu'il suffit de montrer que
  $f(\alpha)\subseteq f(A)$ pour tout $A\in \mathrm{prefix}(f)$, mais cela est
  direct en utilisant le fait que $f$ est croissante et que pour tout
  $A\in \mathrm{prefix}(f)$, $\alpha \subseteq A$. Ainsi
  $f(\alpha)\subseteq \alpha$.

  De plus, comme $f(\alpha)\subseteq \alpha$, on en déduit par croissance de
  $f$ que $f(f(\alpha))\subseteq f(\alpha)$, c'est-à-dire que $f(\alpha)$ est
  lui aussi un élément de $\mathrm{prefix}(f)$ : comme $\alpha$ en est une
  borne inférieure, cela signifie que $\alpha \subseteq f(\alpha)$, d'où en
  utilisant l'inclusion précédente, $f(\alpha) = \alpha$.

  De plus, si $B$ est un point fixe de $f$, alors $f(B)\subseteq B$ donc par
  définition de $\alpha$, $\alpha \subseteq B$.
\end{proof}

\begin{exercise}
  Soit $E$ un ensemble quelconque et $f : \mathcal P(E) \to \mathcal P(E)$ une
  fonction croissante pour l'inclusion, et $A \in \mathcal P(A)$. Montrer que
  l'on peut étendre le théorème pour trouver un plus petit point fixe $\alpha$
  tel que $A\subseteq \alpha$.
\end{exercise}

\begin{exercise}
  Soit $E$ un ensemble quelconque, et $f : \mathcal P(E) \to \mathcal P(E)$ une
  fonction croissante pour l'inclusion. On définit
  $g_f : \mathcal P(E) \to \mathcal P(E)$ par $X \mapsto X \cup f(X)$. Montrer
  que $g_f$ est croissante pour l'inclusion.
\end{exercise}

Des deux exercises précédents, on peut déduire le résultat suivant :

\begin{corollary}[Définition d'une relation inductive]
  Soit une règle $\mathrm r$ sur un ensemble $E$ et une relation $R$. Alors il
  existe une plus petite relation $R_r$ contenant $R$ et stable par $r$. On dit
  alors que cette relation $R_r$ est la relation définie par $r$ sur $R$. Si
  $R = \varnothing$, on dira seulement que la relation est définie par $r$.
\end{corollary}

Cela nous permet alors de définir le principe d'induction sur les relations,
qui est très proche de celui sur les ensembles inductifs.

\begin{theorem}[Induction sur une relation]
  Soit $E$ un ensemble, $R$ une relation $n$-aire sur $E$ et $r$ une règle
  d'inférence incluant comme paramètre $R$. Soit $P \subseteq \mathcal P(E^n)$
  un prédicat d'arité $n$ sur $E$. Supposons que $R\subseteq P$ et que
  $P\models \mathrm r$. Alors $R'\subseteq P$.
\end{theorem}

\begin{proof}
  Il suffit de remarquer que $P$ est un point fixe de $r$ puisque
  $P\models \mathrm r$. Ainsi, comme $P$ est un point fixe de $r$ contenant
  $R$, on en déduit que $P$ contient le plus petit point fixe de $r$ contenant
  $R$, qui est exactement $R'$.
\end{proof}

Ce résultat est essentiel pour prouver beaucoup de résultats : étant donnée une
relation $R$ construite par induction, pour montrer un résultat de la forme
$\forall x_1,\ldots,x_n\in E, R(x_1,\ldots,x_n)\implies P(x_1,\ldots,x_n)$ pour
un certain prédicat $P$, il suffit de montrer que ce prédicat est stable par
la règle le définissant.

\begin{exercise}
  Soient désormais $n$ règles $\mathrm r_1,\ldots,\mathrm r_n$ incluant toutes
  un paramètre $R$ d'arité $p$. Montrer qu'on peut leur associer une fonction
  $r_{1,\ldots,n} : \mathcal P(E^p) \to \mathcal P(E^p)$ croissante. En déduire
  un analogue des propositions précédentes pour un nombre fini de règles.
\end{exercise}

\begin{remark}
  La plupart des relations inductives que nous construirons utilisent plusieurs
  règles, mais l'idée de la construction pour une seule règle suffit. L'exercice
  précédent sert principalement pour justifier au lecteur le plus dubitatif que
  le procédé fonctionne effectivement aussi pour plusieurs règles.
\end{remark}

\begin{exercise}
  Soit une relation $R$ et une règle $\mathrm r$. Montrer que la relation $R'$
  définie par $\mathrm r$ sur $R$ est la même que la relation $R''$ définie
  par la règle $\mathrm r$ et la règle
  \begin{prooftree}
    \AxiomC{$R(x_1,\ldots,x_n)$}
    \UnaryInfC{$R''(x_1,\ldots,x_n)$}
  \end{prooftree}
\end{exercise}

\begin{remark}
  On définira dorénavant des relations inductives seulement par des règles.
\end{remark}

\begin{exercise}
  Soit $A$ un ensemble quelconque. On définit sur $\mathrm{List}(A)$ le prédicat
  $\mathrm{pair}$ par induction avec les règles suivantes :
  \begin{center}
    \begin{prooftree}
      \AxiomC{}
      \UnaryInfC{$\mathrm{pair}(\mathrm{nil})$}
    \end{prooftree}
    \begin{prooftree}
      \AxiomC{$\mathrm{pair}(\ell)$}
      \UnaryInfC{$\mathrm{pair}(\mathrm{cons}(a,\mathrm{cons}(b,\ell)))$}
    \end{prooftree}
  \end{center}
  Montrer l'assertion suivante :
  $$\forall \ell \in \mathrm{List}(A), \mathrm{pair}(\ell) \implies
  \mathrm{pair}(|\ell|)$$
  avec le prédicat $\mathrm{pair}$ sur les entiers défini précédemment.
\end{exercise}

\subsection{Dérivation d'arbre}

Une autre utilité de ce formalisme des règles d'inférences est de permettre de
définir une dérivation, qui est une preuve purement syntaxique qu'une certaine
relation est vérifiée.

\begin{definition}[Dérivation]
  Soit une relation $R$ définie par des règles $r_1,\ldots,r_n$. Une dérivation
  de $R(x_1,\ldots,x_p)$ est un arbre dont la racine est $R(x_1,\ldots,x_p)$ et
  tel que chaque n\oe ud de l'arbre est une règle parmi $r_1,\ldots,r_n$ et
  contient autant de sous-arbres que l'arité de la règle présente.
\end{definition}

\begin{example}
  Soit $A = \{0\}$, dérivons $\mathrm{pair}([0,0,0,0])$ où $[0,0,0,0]$ est une
  abréviation pour
  $\mathrm{cons}(0,\mathrm{cons}(0,\mathrm{cons}(0,\mathrm{cons}(0,
  \mathrm{nil}))))$ :
  \begin{prooftree}
    \AxiomC{}
    \UnaryInfC{$\mathrm{pair}(\mathrm{nil})$}
    \UnaryInfC{$\mathrm{pair}([0,0])$}
    \UnaryInfC{$\mathrm{pari}([0,0,0,0])$}
  \end{prooftree}
\end{example}

Par construction, comme une relation définie par des règles vérifie ces règles,
et étant donnée la définition de \og vérifier une règle\fg{}, il ne fait aucun
doute que si l'on peut dériver $R(x_1,\ldots,x_n)$, alors $R(x_1,\ldots,x_n)$
est vraie.

En logique, nous formalisons les preuves mathématiques comme de tels arbres, car
leur structure simple permet de facilité l'étude du langage mathématique. Si,
dans la réalité, on n'écrit pas une preuve comme une dérivation (nous le
verrons, cette pratique est beaucoup trop laborieuse), il est communément admis
qu'une preuve satisfaisante permet de savoir écrire un tel arbre mentalement.

\'Etudions maintenant la notion de règle admissible et dérivable, correspondant
respectivement à une règle vérifiée par une relation et à une règle dont on peut
syntaxiquement prouver la correspondance avec la règle.

\begin{definition}[Règle admissible]
  Une règle $\mathrm r$ est admissible pour une relation $R$ si
  $R\models \mathrm r$. La règle est admissible pour un ensemble de règles
  $\mathrm r_1,\ldots,\mathrm r_n$ si la relation définie par ces règles vérifie
  la règle $\mathrm r$.
\end{definition}

\begin{definition}[Règle dérivable]
  Soit $R$ une relation définie par les règles $\mathrm r_1,\ldots,\mathrm r_n$,
  une règle $\mathrm r$ est dérivable s'il existe une dérivation de la
  conclusion de $\mathrm r$ utilisant les règles
  $\mathrm r_1,\ldots,\mathrm r_n$ et les prémisses de $\mathrm r$.
\end{definition}

\begin{exercise}
  Montrer qu'une règle dérivable est admissible et que si une règle est
  admissible pour une relation $R$, alors la relation définie par cette règle
  sur $R$ est exactement $R$.
\end{exercise}

\begin{exercise}
  Avec les définitions précédentes, montrer que la règle
  \begin{prooftree}
    \AxiomC{$\mathrm{pair}(\ell)$}
    \UnaryInfC{$\mathrm{pair}([a,b,c,d]\oplus \ell)$}
  \end{prooftree}
  est dérivable. Montrer que la règle
  \begin{prooftree}
    \AxiomC{$\mathrm{pair}(\mathrm{cons}(a,\mathrm{cons}(b,\ell)))$}
    \UnaryInfC{$\mathrm{pair}(\ell)$}
  \end{prooftree}
  est admissible. Est-elle dérivable ?
\end{exercise}

\begin{exercise}
  \'Etant donnée une relation $R$ inductive sur un ensemble $E$ définie par
  des règles $\mathrm r_1,\ldots,\mathrm r_n$, donner une construction analogue
  au principe de récursion pour les ensembles inductifs, permettant de définir
  une fonction $R \to Y$ pour un ensemble $Y$ quelconque.
\end{exercise}
