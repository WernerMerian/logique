\chapter[Induction]{Induction}
\chaptermark{Induction}
\label{chp.induction}

\minitoc

L'un des outils fondamentaux en logique est l'induction. Intuitivement, elle
peut se voir comme une généralisation du principe de récurrence. Nous allons
cependant adopter un formalisme différent de celui utilisé pour faire une simple
récurrence. Les objets principaux sur lesquels nous utiliserons l'induction sont
les ensembles inductifs et les relations inductives, que nous présenterons. Ces
deux objets sont associés à des formalismes différents : le premier aux
grammaire en forme de Backus-Naur, et le deuxième aux points fixes et à la
théorie des treillis. Comme la théorie des treillis sera étudiée plus tard dans
cette partie préliminaire, nous ne traiterons qu'un cas restreint suffisant pour
le travail sur l'induction.

\section{Ensemble inductif}

\subsection{Construction d'un ensemble inductif}

Au niveau intuitif, les ensembles finis semblent avoir une réalité plus
robuste que les ensembles infinis. Il est en effet très facile de se convaincre
à partir de règles simples qu'il existe un ensemble à $3$ éléments, ou à $n$
éléments pour $n$ aussi grand que l'on veut (bien que se convaincre qu'il existe
un ensemble à $300!$ éléments semble légèrement plus long). Cette robustesse
découle du fait qu'on peut explicitement les construire, et cette possibilité
n'existe que pour un ensemble fini. Pourtant, l'ensemble $\mathbb N$ tend aussi
à être plus facilement accepté qu'un ensmeble tel que $\mathbb R / \mathbb Q$.
Un point essentiel qui rend le premier ensemble logiquement plus simple que le
deuxième est qu'il est facile à engendrer : l'ensemble $\mathbb N$ est constitué
de l'élément $0$ et de l'opération $S$ définie par $n \mapsto n + 1$, et tout
autre élément de $\mathbb N$ peut être construit à partir de ces deux éléments.
Sa structure est donc fondamentalement simple, et peut être décrite en des
termes finis.

C'est exactement cette idée de structure générée par des termes finis qui est
formalisée par les ensembles inductifs. Un ensemble inductif va être un ensemble
obtenu par une liste de générateurs, chaque générateur ayant une arité (un
nombre d'objets qu'il prend en entrée). Dans cette définition d'ensemble
inductif, l'exemple canonique est bien sûr $\mathbb N$ lui-même, qu'on peut
définir par :
\begin{itemize}
\item un constructeur sans argument, $0$
\item un constructeur à un argument, $S$
\end{itemize}

Avant de donner la définition d'ensemble inductif, nous allons donner un
formalisme pour parler des constructeurs.

\begin{definition}[Signature]
  Une signature est un couple $C,\alpha$ tel que $\alpha : C \to \mathbb N$.
  On appelle $C$ l'ensemble des constructeurs et, pour $c \in C$, $\alpha(c)$
  est appelé l'arité de $c$.
\end{definition}

Une signature sera généralement donnée sous forme dite de Backus-Naur. Cette
présentation se décompose de la façon suivante :
$$a,b,\ldots ::= \mathrm{cas}\;1 \mid \mathrm{cas}\;2 \mid \ldots$$
où $a,b,\ldots$ représentent les éléments que les constructeurs définissent,
et où chaque cas est la définition d'un nouveau constructeur (ou d'une famille
de constructeurs). Par exemple pour le cas de $\mathbb N$, nous avons :
$$n ::= 0 \mid S\;n$$
Il est fréquent d'employer des variables qui seront quantifiées hors de la
définition à proprement parler, comme
$$l ::= \mathrm{nil} \mid \mathrm{cons}(a,l)$$
où $a \in A$ et $A$ est certain ensemble fixé au préalable. Cette définition
doit se lire comme l'ensemble $(\{\mathrm{nil}\} \cup A,\alpha)$ où $\alpha$
est défini par :
$$
\begin{array}{rcccl}
  \alpha &:& C & \longrightarrow & \mathbb N\\
  & & \mathrm{nil} & \longmapsto & 0 \\
  & & a (\in A) & \longmapsto & 1
\end{array}
$$

Voyons maintenant comment associer à une signature un ensemble généré par les
constructeurs donnés dans la signature. L'ensemble généré doit être un ensemble
$X$ contenant, pour chaque $x_1,\ldots,x_n \in X$ et $c \in C$ d'arité $n$,
l'objet $c(x_1,\ldots,x_n)$, et ne doit contenir que les objets de cette forme.
Nous procédons alors par le bas : un premier ensemble est construit par
l'ensemble $C_0 = \{ c \in C \mid \alpha(c) = 0\}$, puis l'ensemble $C_1$ est
construit par $C_1 = C_0 \cup \{ c(x_1,\ldots,x_n) \mid c \in C, x_1,\ldots,
x_n \in C_0, \alpha(c) = n\}$ et ainsi de suite. Comme $c$ est simplement un
élément dans notre cas, écrire $c(x_1,\ldots,x_n)$ n'a pas de sens, c'est
pourquoi l'on va utiliser à la place $(c,x_1,\ldots,x_n)$.

\begin{definition}[Ensemble inductif sur une signature]
  Soit $(C,\alpha)$ une signature, on définit la suite d'ensembles
  $(X_i)_{i\in\mathbb N}$ par :
  \begin{itemize}
  \item $X_0 = \varnothing$
  \item $X_{n+1} = \{ (c,x_1,\ldots,x_p) \mid c\in C, (x_1,\ldots,x_p)\in (X_n)^p,
    \alpha(c) = p \}$
  \end{itemize}

  L'ensemble inductif engendré par $(C,\alpha)$ est alors l'ensemble
  $$X = \bigcup_{n\in \mathbb N} X_n$$
\end{definition}

La définition donnée n'est pas exactement celle décrite plus haut, mais la
proposition suivante assure que l'union finale génère bien le même ensemble
avec les deux méthodes.

\begin{proposition}
  Soit $(C,\alpha)$ une signature, $X$ l'ensemble inductif engendré par cette
  signature et $(X_n)$ la suite précédemment construite. Alors
  $$\forall n,m \in \mathbb N, n \leq m \implies X_n \subseteq X_m$$
\end{proposition}

\begin{proof}
  On procède par récurrence sur $n$ :
  \begin{itemize}
  \item comme $X_0 = \varnothing$, il est évident que
    $\varnothing \subseteq X_m$ pour tout $m \in\mathbb N$.
  \item supposons que $X_n \subseteq X_m$ pour tout $m \geq n$. Alors
    $$X_{n+1} = \{(c,x_1,\ldots,x_p)\mid c\in C, (x_1,\ldots,x_p)\in(X_n)^p,
    \alpha(c) = p\}$$
    mais par inclusion, comme $(x_1,\ldots,x_p)\in (X_n)^p$, on en déduit que
    $(x_1,\ldots,x_p)$ est aussi dans $(X_m)^p$, pour tout $m \geq n$. Ainsi
    $(c,x_1,\ldots,x_p) \in X_{m+1}$ pour tout $m \geq n$, donc
    $X_{n+1}\subseteq X_m$ pour tout $m \geq n+1$.
  \end{itemize}
\end{proof}

\subsection{Récursion et induction}

Maintenant qu'une construction a été donnée d'un ensemble inductif, il faut
vérifier que le comportement que l'on a décrit est en accord avec le
comportement réel de l'ensemble que l'on a construit. Nous avons dit que
l'ensemble engendré par $(C,\alpha)$ doit contenir exactement les éléments de
la forme $c(x_1,\ldots,x_n)$ où $x_i \in X$ pour tout $i\in\{1,\ldots,n\}$, mais
une autre façon de penser le fait que l'ensemble ne contient que des
applications de constructeurs est le fait qu'une fonction partant d'un ensemble
inductif est exactement spécifiée par son comportement sur les constructeurs.
De telle fonctions sont appelées récursives, car elles peuvent faire appel à
elles-mêmes pour s'appliquer sur les arguments d'un constructeurs, comme nous le
verrons en pratique. Nous verrons ensuite que ce principe de définition
récursive peut se modifier pour donner le principe d'induction, un analogue à
la preuve par récurrence pour un ensemble inductif quelconque.

\begin{theorem}[Propriété universelle des ensembles inductifs]
  Soit $(C,\alpha)$ une signature, et $X$ l'ensemble associé à cette signature.
  Soit un ensemble $Y$ quelconque.
  Soit une famille de fonctions $\{f_c\}_{c\in C}$ telles que pour tout $c\in C$,
  $f_c : Y^{\alpha(c)} \to Y$ (avec la convention que $Y^0 = \{*\}$ est un
  singleton quelconque). Alors il existe une unique fonction $f : X \to Y$
  telle que
  $$\forall c\in C, \forall (x_1,\ldots,x_p)\in X^{\alpha(c)},
  f((c,x_1,\ldots,x_p)) = f_c (f(x_1),\ldots,f(x_p))$$
\end{theorem}

On peut représenter l'équation précédente par le diagramme suivant, où l'égalité
signifie que le diagramme commute, c'est-à-dire que les deux chemins possibles
pour aller d'un coin à l'autre du carré sont égaux.

\begin{center}
  \begin{tikzcd}
    X^{\alpha(c)} \ar[r,"f^{\alpha(c)}"]\ar[d,"c"] & Y^{\alpha(c)} \ar[d,"f_c"] \\
    X \ar[r,"f"] & Y
  \end{tikzcd}
\end{center}

\begin{proof}
  Soit $(X_n)$ la suite d'ensemble construite précédemment pour définir $X$. On
  va prouver par récurrence sur $n$ la proposition suivante :
  $$\forall n\in \mathbb N, \exists ! f : X_n \to Y, \forall c \in C,
  \forall (x_1,\ldots,x_p)\in (X_n)^{\alpha(c)}, f((c,x_1,\ldots,x_p))
  = f_c(f_n(x_1),\ldots,f_n(x_p))$$
  \begin{itemize}
  \item Si $n = 0$, il existe une unique fonction $f_0 : \varnothing \to Y$ et
    elle vérifie la propriété par vacuité.
  \item Soit $n \in \mathbb N$. Supposons qu'il existe une unique fonction
    $f_n : X_n \to Y$ telle que
    $$\forall c\in C, \forall (x_1,\ldots,x_p)\in (X_n)^{\alpha(c)},
    f((c,x_1,\ldots,x_p)) = f_c(f(x_1),\ldots,f(x_p))$$
    On définit alors
    $$\begin{array}{rcccl}
      f_{n+1} &:& X_{n+1} &\longrightarrow & Y \\
      & & (c,x_1,\ldots,x_p) & \longmapsto & f_c(f_n(x_1),\ldots,f_n(x_p))
    \end{array}$$
    On remarque que cette fonction vérifie bien la propriété. De plus, si une
    autre fonction $g$ vérifie la propriété, alors pour $x\in X_{n+1}$, on trouve
    $c\in C$ et $x_1,\ldots,x_p \in X_n$ tels que $x = (c,x_1,\ldots,x_p)$, on a
    alors
    \begin{align*}
      f_{n+1}(x) &= f((c,x_1,\ldots,x_p)) \\
      &= f_c(f_n(x_1),\ldots,f_n(x_n)) \\
      &= g((c,x_1,\ldots,x_p))\\
      &= g (x)
    \end{align*}
    Donc pour tout $x\in X_{n+1}$, $f_{n+1} = g(x)$, ce qui signifie que
    $f_{n+1} = g$, d'où l'unicité de $f_{n+1}$.
  \end{itemize}

  Soit $x \in X$, par définition on trouve $n\in \mathbb N$ tel que $x \in X_n$,
  et on peut donc définir $f(x) = f_n(x)$. Pour montrer que la fonction est
  unique, il suffit de remarquer que toute fonction $X \to Y$ vérifiant les
  prémisses du théorème induit une fonction sur chaque $X_n$, et doit donc
  coïncider avec chaque $f_n$ sur $X_n$.
\end{proof}

\begin{remark}
  Pour une signature $(C,\alpha)$ et un ensemble associé $X$, chaque $c\in C$
  peut maintenant s'interpréter comme une fonction $c : X^{\alpha(c)}\to X$. Nous
  confondrons dorénavant le constructeur et la fonction associée, et écrirons
  donc sans distinction $(c,x_1,\ldots,x_p)$ et $c(x_1,\ldots,x_p)$ pour un
  constructeur $c \in C$.
\end{remark}

Cet outil nous permet maintenant de définir des fonctions dont le domaine est
un ensemble inductif en utilisant sa structure.

\begin{example}
  Donnons un premier exemple de fonction récursive : la fonction
  $d :n\mapsto 2n$, définie de $\mathbb N$ dans $\mathbb N$. En effet, on peut
  la décrire par
  \begin{itemize}
  \item $d(0) = 0$
  \item $d(S\;n) = S\;S\;d(n)$
  \end{itemize}
  nous donnant alors une définition de $d$ grâce au théorème précédent.
\end{example}

\begin{example}
  Un exemple à la fois d'ensemble inductif et de fonction récursive est le
  suivant. Soit $A$ un ensemble quelconque, on définit la signature des listes
  sur $A$ par la grammaire suivante :
  $$\ell ::= \mathrm{nil}\mid \mathrm{cons}(a,\ell)$$
  où $a\in A$. L'ensemble $\mathrm{List}(A)$ est alors l'ensemble inductif
  associé. On définit alors la fonction $|-|$ donnant la longueur d'une
  liste :
  \begin{itemize}
  \item $|\mathrm{nil}| = 0$
  \item $|\mathrm{cons}(a,\ell)| = 1 + |\ell|$
  \end{itemize}
\end{example}

\begin{exercise}
  Soit $A$ un ensemble. Donner une signature définissant l'ensemble
  $\mathrm{BinTree}(A)$ des arbres
  binaires étiquetés par $A$, constitué d'un objet arbre vide et d'un
  constructeur binaire $\mathrm{node}$ prenant en argument un élément $a$ de $A$
  et deux arbres $g$ et $d$ et retournant un nouvel arbre binaire, d'étiquette
  $a$ et dont les deux sous-arbres sont $g$ et $d$.

  Définir une fonction $h : \mathrm{BinTree}(A) \to \mathbb N$ donnant la
  hauteur d'un arbre, c'est-à-dire la longueur du plus long chemin entre la
  racine de l'arbre (la première étiquette) et une feuile (un arbre vide qui est
  sous-arbre). On prend comme convention que $h(\mathrm{nil}) = 0$.

  Définir une fonction $|-| : \mathrm{BinTree}(A) \to \mathbb N$ donnant le
  nombre d'étiquettes d'un arbre.
\end{exercise}

\begin{exercise}
  En utilisant la structure inductive de $\mathbb N$, définir la fonction
  $+ : \mathbb N \times \mathbb N \to \mathbb N$. On pourra pour cela définir
  la fonction $n \mapsto (m \mapsto n + m)$ et faire une fonction récursive sur
  l'argument $n$.
\end{exercise}

Un procédé similaire est celui d'induction. Là où la récursion nous permet de
définir une fonction depuis un ensemble inductif, l'induction va nous permettre
de faire une preuve sur un ensemble inductif. Il s'agit donc, au lieu de donner
une fonction $X \to Y$, de donner un prédicat $P \subseteq X$ et de montrer que
$P = X$.

\begin{theorem}[Principe d'induction]
  Soit $(C,\alpha)$ une signature et $X$ l'ensemble inductif associé. Soit
  $P\subseteq X$ un prédicat sur $X$. Si pour tous $c\in C$ et
  $x_1,\ldots,x_p\in X^{\alpha(c)}$, la propriété
  $$x_1\in P \text{ et } x_2\in P \text{ et }\ldots \text{ et }x_p\in P \implies
  c(x_1,\ldots,x_p)\in P$$ est vérifiée,
  alors $P = X$.
\end{theorem}

\begin{proof}
  Pour prouver ce résultat, il suffit de montrer que pour tout $n\in\mathbb N$,
  $X_n \subseteq P$ pour $(X_n)$ la suite d'ensembles construisant $X$. En
  effectuant une récurrences sur $n$ :
  \begin{itemize}
  \item Si $n = 0$, alors $\varnothing \subseteq P$.
  \item Supposons que $X_n \subseteq P$ pour $n \in \mathbb N$. Soit
    $x \in X_{n+1}$. Par définition de $X_{n+1}$, on trouve $c \in C$ et
    $x_1,\ldots,x_p \in X_n$ tels que $x = c(x_1,\ldots,x_p)$. Par hypothèse
    de récurrence, on en déduit que pour tout $i\in\{1,\ldots,p\}$, $x_i\in P$.
    Il vient donc, avec l'hypothèse du théorème sur $P$, que
    $c(x_1,\ldots,x_p)\in P$.

    On en conclus que $P\subseteq X_{n+1}$.
  \end{itemize}

  Ainsi, par récurrence, pour tout $n\in \mathbb N$, $X_n \subseteq P$.
  Cela montre alors que
  $$\bigcup_{n \in \mathbb N} X_n \subseteq P$$
  ce qu'il fallait démontrer.
\end{proof}

On peut affiner ce résultat en distinguant deux sortes de constructeurs : d'un
côté les constructeurs d'arité $0$, qui sont des constantes, et de l'autre les
constructeurs d'arité supérieure à $1$. Le théorème précédent nous dit que pour
prouver une proposition $P$ sur un ensemble inductif, il suffit de prouver qu'il
contient les constantes et qu'il est stable par chaque constructeur. On remarque
que dans le cas de $\mathbb N$, engendré par $0$ et $S$, ce principe nous dit
qu'une partie $P$ contenant $0$ et telle que
$\forall n\in\mathbb N, n\in P \implies n+1\in P$ est exactement $\mathbb N$ :
c'est le principe de récurrence.

Ainsi, puisque nous prouvons le principe d'induction à partir du principe de
récurrence, et puisque le principe de récurrence est un cas particulier du
principe d'induction, les deux sont logiquement équivalents. L'induction,
cependant, est conceptuellement plus intéressante puisqu'elle peut s'utiliser
dans plus de cas.

\begin{exercise}
  On considère $\mathbb N$ comme un ensemble inductif, et la fonction $d$
  définie dans un exemple précédent. Montrer que pour tout $n \in \mathbb N$,
  $d(n)$ est pair. On prendra comme définition de pair le prédicat
  $\mathrm{pair}(n) \defeq \exists m\in\mathbb N, n = 2 \times m$.
\end{exercise}

\begin{exercise}
  Soit un ensemble $A$. On définit
  $\oplus : \mathrm{List}(A) \times \mathrm{List}(A)\to \mathrm{List}(A)$ par
  induction sur le premier argument:
  \begin{itemize}
  \item Pour tout $\ell\in \mathrm{List}(A)$, $\mathrm{nil} \oplus \ell = \ell$.
  \item Pour tous $\ell,\ell'\in\mathrm{List}(A), a\in A$,
    $\mathrm{cons}(a,\ell) \oplus \ell' = \mathrm{cons}(a,\ell \oplus \ell')$.
  \end{itemize}

  Montrer que
  $$\forall \ell,\ell'\in \mathrm{List}(A), |\ell\oplus \ell'|=|\ell|+|\ell'|$$
\end{exercise}

\section{Relation inductive}

\subsection{Construction d'une relation inductive}

Une façon de considérer les ensembles inductif est, étant donnée une signature,
de prendre le plus petit ensemble stable par les constructeurs de cette
signature. Le problème, pour faire cela, est que nous n'avons d'ensemble sur
lequelle travailler a priori. C'est pourquoi la construction précédente
définissait chaque ensemble intermédiaire pour en prendre l'union. Au contraire,
pour définir les relations inductives, nous avons un ensemble ambiant et nous
pouvons donc travailler sur la notion de plus petit ensemble stable. Pour
pouvoir mieux appréhender les relations inductives, nous allons directement
introduire les règles d'inférence.

\begin{definition}[Règle d'inférence]
  On appelle règle d'inférence une présentation de la forme suivante:
  \begin{prooftree}
    \AxiomC{$P_1$}
    \AxiomC{$P_2$}
    \AxiomC{$\cdots$}
    \AxiomC{$P_n$}
    \QuaternaryInfC{$P$}
  \end{prooftree}
  Où $P_1,\ldots,P_n$ sont appelées les prémisses de la règle, et $P$ est
  appelée la conclusion de la règle. On dit que la règle est juste si, lorsque
  toutes les prémisses de la règle sont vérifiées, alors la conclusion est aussi
  vérifiée.

  Une règle peut contenir plusieurs paramètres, par exemple
  \begin{prooftree}
    \AxiomC{$a = b$}
    \AxiomC{$P(a)$}
    \BinaryInfC{$P(b)$}
  \end{prooftree}
  auquel cas la règle est juste lorsqu'elle est juste pour chaque instance
  possible de ces paramètres. Dans l'exemple, on suppose que $a$ et $b$ sont
  quantifiés sur un certain ensemble $A$, et la règle est donc juste lorsque
  $\forall a,b\in A, ((a = b) \text{ et } P(a)) \implies P(b)$.
\end{definition}

Rappelons la définition d'une relation.

\begin{definition}[Relation]
  Soit $X$ un ensemble. On appelle relation sur $X$ une partie $R\subseteq X^n$
  où $n\in\mathbb N$ est appelé l'arité de la relation $R$.
\end{definition}

Une relation 
